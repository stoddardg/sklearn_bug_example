{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This notebook documents a minimal working example of the \"ValueError: Buffer source array is read-only\" that I get when setting `n_jobs > 1` in `GridSearchCV`.  \n",
    "\n",
    "The use case is the following: I have a dataframe with a mix of string and numeric columns. I build a Pipeline that first encodes the data properly and then passes the encoded data into a classifier. I encode the data using a custom class called `DataFrame_Encoder` to specify which columns should be one-hot encoded with DictVectorizer and which columns should be kept as is. I then pass that Pipeline into GridSearchCV to optimize over the hyperparameters of the classifier. \n",
    "\n",
    "This snippet crashes when `n_jobs > 1` in `GridSearchCV` and the dataset is large (breaks somewhere between 100K and 200K rows but I haven't found the exact breaking point. \n",
    "\n",
    "The error occurs whenever a Dataframe that contains a column of dtype Object is passed to `GridSearchCV.fit`. I initially believed that the error was caused by my custom `DataFrame_Encoder` class but I no longer that is the case. The code breaks prior to ever calling the `fit` or `transform` methods of `DataFrame_Encoder`. I think the error is happening as soon as `GridSearchCV.fit` is called. Perhaps there's a check that works successfully for non-Object columns but doesn't work for Object columns. \n",
    "\n",
    "- Example 1 shows the MWE that results in the ValueError\n",
    "- Example 2&3 show that the error is not caused by my custom DataFrame_Encoder class.\n",
    "- Example 4 shows that things work if you drop the Object column from the Dataframe. \n",
    "- Example 5 shows that things work if you decrease the number of rows in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Related issues\n",
    "\n",
    "This bug seems to be related to the following issues: \n",
    "\n",
    "- https://github.com/pandas-dev/pandas/issues/9928#issuecomment-97038944\n",
    "- https://github.com/scikit-learn/scikit-learn/issues/4772\n",
    "- https://github.com/scikit-learn/scikit-learn/pull/4775\n",
    "\n",
    "It seems like it was supposed to be fixed in a recent version, so perhaps this is separate thing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataFrame_Encoder(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, categorical_cols_=None,numeric_cols_=None):\n",
    "        print(\"__init__ called\")\n",
    "        self.categorical_cols_ = categorical_cols_\n",
    "        self.numeric_cols_ = numeric_cols_\n",
    "    \n",
    "    def fit(self, df, y=None):\n",
    "        print(\"Fit called\")\n",
    "        ### df should be a dataframe that is a mix of categorical and numeric columns\n",
    "        self.vec_ = DictVectorizer(sparse=False)\n",
    "        temp_data = df[self.categorical_cols_].astype(str)\n",
    "        self.vec_.fit(temp_data.to_dict('records'))\n",
    "        self.feature_names_ = list(self.numeric_cols_) + list(self.vec_.feature_names_)\n",
    "        return self\n",
    "\n",
    "    def transform(self, df):\n",
    "        ### df should be a dataframe that is a mix of categorical and numeric columns\n",
    "        print(\"Transform called\")\n",
    "        temp_data = df[self.categorical_cols_].astype(str)\n",
    "        categorical_data = self.vec_.transform(temp_data.to_dict('records'))\n",
    "        categorical_df = pd.DataFrame(categorical_data, columns=self.vec_.feature_names_, index=df.index)\n",
    "        new_data = pd.concat([df[self.numeric_cols_], categorical_df],axis=1)\n",
    "        return new_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1 : Fails "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__ called\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "__init__ called\n",
      "__init__ called"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/utils/__init__.py:104: DataConversionWarning: Copying input dataframe for slicing.\n",
      "  DataConversionWarning)\n",
      "/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/utils/__init__.py:104: DataConversionWarning: Copying input dataframe for slicing.\n",
      "  DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "__init__ called\n",
      "__init__ called\n",
      "__init__ called\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/utils/__init__.py:104: DataConversionWarning: Copying input dataframe for slicing.\n",
      "  DataConversionWarning)\n",
      "/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/utils/__init__.py:104: DataConversionWarning: Copying input dataframe for slicing.\n",
      "  DataConversionWarning)\n"
     ]
    },
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x10e8bd030, file \"/Use...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/Users/gstoddard/anaconda/envs/standard_py3_env/...ges/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/Users/gstod.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x10e8bd030, file \"/Use...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/Users/gstoddard/anaconda/envs/standard_py3_env/...ges/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/Users/gstod.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n     17 \n     18 \n     19 \n     20 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 5\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 5), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 5)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=5)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'x,y = make_classification(n_samples=200000,n_fea...ram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 8, 2, 22, 24, 59, 88163, tzinfo=tzutc()), 'msg_id': '81F1F7C9D6BE4AB79A8ED2592D8F62FE', 'msg_type': 'execute_request', 'session': 'A09FD675E3EA46CB837CBE1D3E75F32E', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '81F1F7C9D6BE4AB79A8ED2592D8F62FE', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'A09FD675E3EA46CB837CBE1D3E75F32E']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'x,y = make_classification(n_samples=200000,n_fea...ram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 8, 2, 22, 24, 59, 88163, tzinfo=tzutc()), 'msg_id': '81F1F7C9D6BE4AB79A8ED2592D8F62FE', 'msg_type': 'execute_request', 'session': 'A09FD675E3EA46CB837CBE1D3E75F32E', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '81F1F7C9D6BE4AB79A8ED2592D8F62FE', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'A09FD675E3EA46CB837CBE1D3E75F32E'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'x,y = make_classification(n_samples=200000,n_fea...ram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 8, 2, 22, 24, 59, 88163, tzinfo=tzutc()), 'msg_id': '81F1F7C9D6BE4AB79A8ED2592D8F62FE', 'msg_type': 'execute_request', 'session': 'A09FD675E3EA46CB837CBE1D3E75F32E', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '81F1F7C9D6BE4AB79A8ED2592D8F62FE', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='x,y = make_classification(n_samples=200000,n_fea...ram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)\\n', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'x,y = make_classification(n_samples=200000,n_fea...ram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)\\n'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('x,y = make_classification(n_samples=200000,n_fea...ram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)\\n',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('x,y = make_classification(n_samples=200000,n_fea...ram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)\\n',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='x,y = make_classification(n_samples=200000,n_fea...ram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)\\n', store_history=True, silent=False, shell_futures=True)\n   2678                 self.displayhook.exec_result = result\n   2679 \n   2680                 # Execute the user code\n   2681                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2682                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2683                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2684                 \n   2685                 self.last_execution_succeeded = not has_raised\n   2686 \n   2687                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-3-b63d72744ba1>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 119404c50, execution_..._before_exec=None error_in_exec=None result=None>)\n   2788                     return True\n   2789 \n   2790             for i, node in enumerate(to_run_interactive):\n   2791                 mod = ast.Interactive([node])\n   2792                 code = compiler(mod, cell_name, \"single\")\n-> 2793                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x1193a4f60, file \"<ipython-input-3-b63d72744ba1>\", line 20>\n        result = <ExecutionResult object at 119404c50, execution_..._before_exec=None error_in_exec=None result=None>\n   2794                     return True\n   2795 \n   2796             # Flush softspace\n   2797             if softspace(sys.stdout, 0):\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x1193a4f60, file \"<ipython-input-3-b63d72744ba1>\", line 20>, result=<ExecutionResult object at 119404c50, execution_..._before_exec=None error_in_exec=None result=None>)\n   2842         outflag = True  # happens in more places, so it's easier as default\n   2843         try:\n   2844             try:\n   2845                 self.hooks.pre_run_code_hook()\n   2846                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2847                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x1193a4f60, file \"<ipython-input-3-b63d72744ba1>\", line 20>\n        self.user_global_ns = {'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'DataFrame_Encoder': <class '__main__.DataFrame_Encoder'>, 'DictVectorizer': <class 'sklearn.feature_extraction.dict_vectorizer.DictVectorizer'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import pandas as pd\\n\\nfrom sklearn.model_selectio...raction import DictVectorizer\\n\\nimport numpy as np', 'class DataFrame_Encoder(BaseEstimator, Transform..., categorical_df],axis=1)\\n        return new_data', 'x,y = make_classification(n_samples=200000,n_fea...aram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)'], 'Out': {}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'TransformerMixin': <class 'sklearn.base.TransformerMixin'>, '_': '', ...}\n        self.user_ns = {'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'DataFrame_Encoder': <class '__main__.DataFrame_Encoder'>, 'DictVectorizer': <class 'sklearn.feature_extraction.dict_vectorizer.DictVectorizer'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import pandas as pd\\n\\nfrom sklearn.model_selectio...raction import DictVectorizer\\n\\nimport numpy as np', 'class DataFrame_Encoder(BaseEstimator, Transform..., categorical_df],axis=1)\\n        return new_data', 'x,y = make_classification(n_samples=200000,n_fea...aram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)'], 'Out': {}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'TransformerMixin': <class 'sklearn.base.TransformerMixin'>, '_': '', ...}\n   2848             finally:\n   2849                 # Reset our crash handler in place\n   2850                 sys.excepthook = old_excepthook\n   2851         except SystemExit as e:\n\n...........................................................................\n/Users/gstoddard/sklearn_bug/<ipython-input-3-b63d72744ba1> in <module>()\n     15 ])\n     16 pipeline.set_params(feature_encoder__categorical_cols_=string_features, feature_encoder__numeric_cols_=numeric_features)\n     17 \n     18 clf = GridSearchCV(pipeline, param_grid,cv=5,n_jobs=2,verbose=1)\n     19 \n---> 20 clf.fit(df,y)\n     21 \n     22 \n     23 \n     24 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...train_score=True,\n       scoring=None, verbose=1), X=              x1        x2        x3        x4  ...849 -0.190363        a\n\n[200000 rows x 6 columns], y=array([0, 0, 1, ..., 1, 0, 1]), groups=None)\n    940 \n    941         groups : array-like, with shape (n_samples,), optional\n    942             Group labels for the samples used while splitting the dataset into\n    943             train/test set.\n    944         \"\"\"\n--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))\n        self._fit = <bound method BaseSearchCV._fit of GridSearchCV(...rain_score=True,\n       scoring=None, verbose=1)>\n        X =               x1        x2        x3        x4  ...849 -0.190363        a\n\n[200000 rows x 6 columns]\n        y = array([0, 0, 1, ..., 1, 0, 1])\n        groups = None\n        self.param_grid = {'clf__n_estimators': [10, 100]}\n    946 \n    947 \n    948 class RandomizedSearchCV(BaseSearchCV):\n    949     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...train_score=True,\n       scoring=None, verbose=1), X=              x1        x2        x3        x4  ...849 -0.190363        a\n\n[200000 rows x 6 columns], y=array([0, 0, 1, ..., 1, 0, 1]), groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)\n    559                                   fit_params=self.fit_params,\n    560                                   return_train_score=self.return_train_score,\n    561                                   return_n_test_samples=True,\n    562                                   return_times=True, return_parameters=True,\n    563                                   error_score=self.error_score)\n--> 564           for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>\n    565           for train, test in cv_iter)\n    566 \n    567         # if one choose to see train score, \"out\" will contain train score info\n    568         if self.return_train_score:\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=2), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=2)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Wed Aug  2 18:25:00 2017\nPID: 35261Python 3.6.1: /Users/gstoddard/anaconda/envs/standard_py3_env/bin/python\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('feature_encoder', DataFrame_En...None,\n            verbose=0, warm_start=False))]),               x1        x2        x3        x4  ...849 -0.190363        a\n\n[200000 rows x 6 columns], memmap([0, 0, 1, ..., 1, 0, 1]), <function _passthrough_scorer>, memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999]), array([    0,     1,     2, ..., 40133, 40138, 40141]), 1, {'clf__n_estimators': 10}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('feature_encoder', DataFrame_En...None,\n            verbose=0, warm_start=False))]),               x1        x2        x3        x4  ...849 -0.190363        a\n\n[200000 rows x 6 columns], memmap([0, 0, 1, ..., 1, 0, 1]), <function _passthrough_scorer>, memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999]), array([    0,     1,     2, ..., 40133, 40138, 40141]), 1, {'clf__n_estimators': 10})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('feature_encoder', DataFrame_En...None,\n            verbose=0, warm_start=False))]), X=              x1        x2        x3        x4  ...849 -0.190363        a\n\n[200000 rows x 6 columns], y=memmap([0, 0, 1, ..., 1, 0, 1]), scorer=<function _passthrough_scorer>, train=memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999]), test=array([    0,     1,     2, ..., 40133, 40138, 40141]), verbose=1, parameters={'clf__n_estimators': 10}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    226     if parameters is not None:\n    227         estimator.set_params(**parameters)\n    228 \n    229     start_time = time.time()\n    230 \n--> 231     X_train, y_train = _safe_split(estimator, X, y, train)\n        X_train = undefined\n        y_train = undefined\n        estimator = Pipeline(steps=[('feature_encoder', DataFrame_En...None,\n            verbose=0, warm_start=False))])\n        X =               x1        x2        x3        x4  ...849 -0.190363        a\n\n[200000 rows x 6 columns]\n        y = memmap([0, 0, 1, ..., 1, 0, 1])\n        train = memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999])\n    232     X_test, y_test = _safe_split(estimator, X, y, test, train)\n    233 \n    234     try:\n    235         if y_train is None:\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/utils/metaestimators.py in _safe_split(estimator=Pipeline(steps=[('feature_encoder', DataFrame_En...None,\n            verbose=0, warm_start=False))]), X=              x1        x2        x3        x4  ...849 -0.190363        a\n\n[200000 rows x 6 columns], y=memmap([0, 0, 1, ..., 1, 0, 1]), indices=memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999]), train_indices=None)\n    103             if train_indices is None:\n    104                 X_subset = X[np.ix_(indices, indices)]\n    105             else:\n    106                 X_subset = X[np.ix_(indices, train_indices)]\n    107         else:\n--> 108             X_subset = safe_indexing(X, indices)\n        X_subset = undefined\n        X =               x1        x2        x3        x4  ...849 -0.190363        a\n\n[200000 rows x 6 columns]\n        indices = memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999])\n    109 \n    110     if y is not None:\n    111         y_subset = safe_indexing(y, indices)\n    112     else:\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/utils/__init__.py in safe_indexing(X=              x1        x2        x3        x4  ...849 -0.190363        a\n\n[200000 rows x 6 columns], indices=memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999]))\n    100         except ValueError:\n    101             # Cython typed memoryviews internally used in pandas do not support\n    102             # readonly buffers.\n    103             warnings.warn(\"Copying input dataframe for slicing.\",\n    104                           DataConversionWarning)\n--> 105             return X.copy().iloc[indices]\n        X.copy.iloc = undefined\n        indices = memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999])\n    106     elif hasattr(X, \"shape\"):\n    107         if hasattr(X, 'take') and (hasattr(indices, 'dtype') and\n    108                                    indices.dtype.kind == 'i'):\n    109             # This is often substantially faster than X[indices]\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self=<pandas.core.indexing._iLocIndexer object>, key=memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999]))\n   1323             except (KeyError, IndexError):\n   1324                 pass\n   1325             return self._getitem_tuple(key)\n   1326         else:\n   1327             key = com._apply_if_callable(key, self.obj)\n-> 1328             return self._getitem_axis(key, axis=0)\n        self._getitem_axis = <bound method _iLocIndexer._getitem_axis of <pandas.core.indexing._iLocIndexer object>>\n        key = memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999])\n   1329 \n   1330     def _is_scalar_access(self, key):\n   1331         raise NotImplementedError()\n   1332 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self=<pandas.core.indexing._iLocIndexer object>, key=memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999]), axis=0)\n   1733             self._has_valid_type(key, axis)\n   1734             return self._getbool_axis(key, axis=axis)\n   1735 \n   1736         # a list of integers\n   1737         elif is_list_like_indexer(key):\n-> 1738             return self._get_list_axis(key, axis=axis)\n        self._get_list_axis = <bound method _iLocIndexer._get_list_axis of <pandas.core.indexing._iLocIndexer object>>\n        key = memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999])\n        axis = 0\n   1739 \n   1740         # a single integer\n   1741         else:\n   1742             key = self._convert_scalar_indexer(key, axis)\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/indexing.py in _get_list_axis(self=<pandas.core.indexing._iLocIndexer object>, key=memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999]), axis=0)\n   1710         Returns\n   1711         -------\n   1712         Series object\n   1713         \"\"\"\n   1714         try:\n-> 1715             return self.obj.take(key, axis=axis, convert=False)\n        self.obj.take = <bound method NDFrame.take of               x1  ...49 -0.190363        a\n\n[200000 rows x 6 columns]>\n        key = memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999])\n        axis = 0\n   1716         except IndexError:\n   1717             # re-raise with different error message\n   1718             raise IndexError(\"positional indexers are out-of-bounds\")\n   1719 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/generic.py in take(self=              x1        x2        x3        x4  ...849 -0.190363        a\n\n[200000 rows x 6 columns], indices=memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999]), axis=0, convert=False, is_copy=True, **kwargs={})\n   1923         \"\"\"\n   1924         nv.validate_take(tuple(), kwargs)\n   1925         self._consolidate_inplace()\n   1926         new_data = self._data.take(indices,\n   1927                                    axis=self._get_block_manager_axis(axis),\n-> 1928                                    convert=True, verify=True)\n        convert = False\n   1929         result = self._constructor(new_data).__finalize__(self)\n   1930 \n   1931         # maybe set copy if we didn't actually change the index\n   1932         if is_copy:\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py in take(self=BlockManager\nItems: Index(['x1', 'x2', 'x3', 'x4...tBlock: slice(5, 6, 1), 1 x 200000, dtype: object, indexer=memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999]), axis=1, verify=True, convert=True)\n   4006                 raise Exception('Indices must be nonzero and less than '\n   4007                                 'the axis length')\n   4008 \n   4009         new_labels = self.axes[axis].take(indexer)\n   4010         return self.reindex_indexer(new_axis=new_labels, indexer=indexer,\n-> 4011                                     axis=axis, allow_dups=True)\n        axis = 1\n   4012 \n   4013     def merge(self, other, lsuffix='', rsuffix=''):\n   4014         if not self._is_indexed_like(other):\n   4015             raise AssertionError('Must have same axes to merge managers')\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py in reindex_indexer(self=BlockManager\nItems: Index(['x1', 'x2', 'x3', 'x4...tBlock: slice(5, 6, 1), 1 x 200000, dtype: object, new_axis=Int64Index([ 39890,  39891,  39892,  39893,  398...199999],\n           dtype='int64', length=159999), indexer=memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999]), axis=1, fill_value=None, allow_dups=True, copy=True)\n   3892             new_blocks = self._slice_take_blocks_ax0(indexer,\n   3893                                                      fill_tuple=(fill_value,))\n   3894         else:\n   3895             new_blocks = [blk.take_nd(indexer, axis=axis, fill_tuple=(\n   3896                 fill_value if fill_value is not None else blk.fill_value,))\n-> 3897                 for blk in self.blocks]\n        self.blocks = (FloatBlock: slice(0, 5, 1), 5 x 200000, dtype: float64, ObjectBlock: slice(5, 6, 1), 1 x 200000, dtype: object)\n   3898 \n   3899         new_axes = list(self.axes)\n   3900         new_axes[axis] = new_axis\n   3901         return self.__class__(new_blocks, new_axes)\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py in <listcomp>(.0=<tuple_iterator object>)\n   3892             new_blocks = self._slice_take_blocks_ax0(indexer,\n   3893                                                      fill_tuple=(fill_value,))\n   3894         else:\n   3895             new_blocks = [blk.take_nd(indexer, axis=axis, fill_tuple=(\n   3896                 fill_value if fill_value is not None else blk.fill_value,))\n-> 3897                 for blk in self.blocks]\n        blk = FloatBlock: slice(0, 5, 1), 5 x 200000, dtype: float64\n   3898 \n   3899         new_axes = list(self.axes)\n   3900         new_axes[axis] = new_axis\n   3901         return self.__class__(new_blocks, new_axes)\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py in take_nd(self=FloatBlock: slice(0, 5, 1), 5 x 200000, dtype: float64, indexer=memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999]), axis=1, new_mgr_locs=None, fill_tuple=(nan,))\n   1041             new_values = algos.take_nd(values, indexer, axis=axis,\n   1042                                        allow_fill=False)\n   1043         else:\n   1044             fill_value = fill_tuple[0]\n   1045             new_values = algos.take_nd(values, indexer, axis=axis,\n-> 1046                                        allow_fill=True, fill_value=fill_value)\n        fill_value = nan\n   1047 \n   1048         if new_mgr_locs is None:\n   1049             if axis == 0:\n   1050                 slc = lib.indexer_as_slice(indexer)\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/algorithms.py in take_nd(arr=memmap([[-0.26666035, -0.23195333, -1.14554448, ... 0.064569  ,\n         -0.07119485, -0.1903627 ]]), indexer=memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999]), axis=1, out=array([[-0.70387825,  0.01771368, -0.14068663, ....  1.11458733,\n         1.00384929, -0.1903627 ]]), fill_value=nan, mask_info=None, allow_fill=True)\n   1466         else:\n   1467             out = np.empty(out_shape, dtype=dtype)\n   1468 \n   1469     func = _get_take_nd_function(arr.ndim, arr.dtype, out.dtype, axis=axis,\n   1470                                  mask_info=mask_info)\n-> 1471     func(arr, indexer, out, fill_value)\n        func = <built-in function take_2d_axis1_float64_float64>\n        arr = memmap([[-0.26666035, -0.23195333, -1.14554448, ... 0.064569  ,\n         -0.07119485, -0.1903627 ]])\n        indexer = memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999])\n        out = array([[-0.70387825,  0.01771368, -0.14068663, ....  1.11458733,\n         1.00384929, -0.1903627 ]])\n        fill_value = nan\n   1472 \n   1473     if flip_order:\n   1474         out = out.T\n   1475     return out\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/_libs/algos.cpython-36m-darwin.so in pandas._libs.algos.take_2d_axis1_float64_float64 (pandas/_libs/algos.c:111160)()\n   4629 \n   4630 \n   4631 \n   4632 \n   4633 \n-> 4634 \n   4635 \n   4636 \n   4637 \n   4638 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/_libs/algos.cpython-36m-darwin.so in View.MemoryView.memoryview_cwrapper (pandas/_libs/algos.c:124730)()\n    639 \n    640 \n    641 \n    642 \n    643 \n--> 644 \n    645 \n    646 \n    647 \n    648 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/_libs/algos.cpython-36m-darwin.so in View.MemoryView.memoryview.__cinit__ (pandas/_libs/algos.c:120965)()\n    340 \n    341 \n    342 \n    343 \n    344 \n--> 345 \n    346 \n    347 \n    348 \n    349 \n\nValueError: buffer source array is read-only\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/utils/__init__.py\", line 99, in safe_indexing\n    return X.iloc[indices]\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/indexing.py\", line 1328, in __getitem__\n    return self._getitem_axis(key, axis=0)\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/indexing.py\", line 1738, in _getitem_axis\n    return self._get_list_axis(key, axis=axis)\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/indexing.py\", line 1715, in _get_list_axis\n    return self.obj.take(key, axis=axis, convert=False)\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/generic.py\", line 1928, in take\n    convert=True, verify=True)\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py\", line 4011, in take\n    axis=axis, allow_dups=True)\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py\", line 3897, in reindex_indexer\n    for blk in self.blocks]\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py\", line 3897, in <listcomp>\n    for blk in self.blocks]\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py\", line 1046, in take_nd\n    allow_fill=True, fill_value=fill_value)\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/algorithms.py\", line 1471, in take_nd\n    func(arr, indexer, out, fill_value)\n  File \"pandas/_libs/algos_take_helper.pxi\", line 4809, in pandas._libs.algos.take_2d_axis0_object_object (pandas/_libs/algos.c:112602)\n  File \"stringsource\", line 644, in View.MemoryView.memoryview_cwrapper (pandas/_libs/algos.c:124730)\n  File \"stringsource\", line 345, in View.MemoryView.memoryview.__cinit__ (pandas/_libs/algos.c:120965)\nValueError: buffer source array is read-only\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 344, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 231, in _fit_and_score\n    X_train, y_train = _safe_split(estimator, X, y, train)\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/utils/metaestimators.py\", line 108, in _safe_split\n    X_subset = safe_indexing(X, indices)\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/utils/__init__.py\", line 105, in safe_indexing\n    return X.copy().iloc[indices]\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/indexing.py\", line 1328, in __getitem__\n    return self._getitem_axis(key, axis=0)\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/indexing.py\", line 1738, in _getitem_axis\n    return self._get_list_axis(key, axis=axis)\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/indexing.py\", line 1715, in _get_list_axis\n    return self.obj.take(key, axis=axis, convert=False)\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/generic.py\", line 1928, in take\n    convert=True, verify=True)\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py\", line 4011, in take\n    axis=axis, allow_dups=True)\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py\", line 3897, in reindex_indexer\n    for blk in self.blocks]\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py\", line 3897, in <listcomp>\n    for blk in self.blocks]\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py\", line 1046, in take_nd\n    allow_fill=True, fill_value=fill_value)\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/algorithms.py\", line 1471, in take_nd\n    func(arr, indexer, out, fill_value)\n  File \"pandas/_libs/algos_take_helper.pxi\", line 4634, in pandas._libs.algos.take_2d_axis1_float64_float64 (pandas/_libs/algos.c:111160)\n  File \"stringsource\", line 644, in View.MemoryView.memoryview_cwrapper (pandas/_libs/algos.c:124730)\n  File \"stringsource\", line 345, in View.MemoryView.memoryview.__cinit__ (pandas/_libs/algos.c:120965)\nValueError: buffer source array is read-only\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 353, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nValueError                                         Wed Aug  2 18:25:00 2017\nPID: 35261Python 3.6.1: /Users/gstoddard/anaconda/envs/standard_py3_env/bin/python\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('feature_encoder', DataFrame_En...None,\n            verbose=0, warm_start=False))]),               x1        x2        x3        x4  ...849 -0.190363        a\n\n[200000 rows x 6 columns], memmap([0, 0, 1, ..., 1, 0, 1]), <function _passthrough_scorer>, memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999]), array([    0,     1,     2, ..., 40133, 40138, 40141]), 1, {'clf__n_estimators': 10}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('feature_encoder', DataFrame_En...None,\n            verbose=0, warm_start=False))]),               x1        x2        x3        x4  ...849 -0.190363        a\n\n[200000 rows x 6 columns], memmap([0, 0, 1, ..., 1, 0, 1]), <function _passthrough_scorer>, memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999]), array([    0,     1,     2, ..., 40133, 40138, 40141]), 1, {'clf__n_estimators': 10})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('feature_encoder', DataFrame_En...None,\n            verbose=0, warm_start=False))]), X=              x1        x2        x3        x4  ...849 -0.190363        a\n\n[200000 rows x 6 columns], y=memmap([0, 0, 1, ..., 1, 0, 1]), scorer=<function _passthrough_scorer>, train=memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999]), test=array([    0,     1,     2, ..., 40133, 40138, 40141]), verbose=1, parameters={'clf__n_estimators': 10}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    226     if parameters is not None:\n    227         estimator.set_params(**parameters)\n    228 \n    229     start_time = time.time()\n    230 \n--> 231     X_train, y_train = _safe_split(estimator, X, y, train)\n        X_train = undefined\n        y_train = undefined\n        estimator = Pipeline(steps=[('feature_encoder', DataFrame_En...None,\n            verbose=0, warm_start=False))])\n        X =               x1        x2        x3        x4  ...849 -0.190363        a\n\n[200000 rows x 6 columns]\n        y = memmap([0, 0, 1, ..., 1, 0, 1])\n        train = memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999])\n    232     X_test, y_test = _safe_split(estimator, X, y, test, train)\n    233 \n    234     try:\n    235         if y_train is None:\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/utils/metaestimators.py in _safe_split(estimator=Pipeline(steps=[('feature_encoder', DataFrame_En...None,\n            verbose=0, warm_start=False))]), X=              x1        x2        x3        x4  ...849 -0.190363        a\n\n[200000 rows x 6 columns], y=memmap([0, 0, 1, ..., 1, 0, 1]), indices=memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999]), train_indices=None)\n    103             if train_indices is None:\n    104                 X_subset = X[np.ix_(indices, indices)]\n    105             else:\n    106                 X_subset = X[np.ix_(indices, train_indices)]\n    107         else:\n--> 108             X_subset = safe_indexing(X, indices)\n        X_subset = undefined\n        X =               x1        x2        x3        x4  ...849 -0.190363        a\n\n[200000 rows x 6 columns]\n        indices = memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999])\n    109 \n    110     if y is not None:\n    111         y_subset = safe_indexing(y, indices)\n    112     else:\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/utils/__init__.py in safe_indexing(X=              x1        x2        x3        x4  ...849 -0.190363        a\n\n[200000 rows x 6 columns], indices=memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999]))\n    100         except ValueError:\n    101             # Cython typed memoryviews internally used in pandas do not support\n    102             # readonly buffers.\n    103             warnings.warn(\"Copying input dataframe for slicing.\",\n    104                           DataConversionWarning)\n--> 105             return X.copy().iloc[indices]\n        X.copy.iloc = undefined\n        indices = memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999])\n    106     elif hasattr(X, \"shape\"):\n    107         if hasattr(X, 'take') and (hasattr(indices, 'dtype') and\n    108                                    indices.dtype.kind == 'i'):\n    109             # This is often substantially faster than X[indices]\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self=<pandas.core.indexing._iLocIndexer object>, key=memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999]))\n   1323             except (KeyError, IndexError):\n   1324                 pass\n   1325             return self._getitem_tuple(key)\n   1326         else:\n   1327             key = com._apply_if_callable(key, self.obj)\n-> 1328             return self._getitem_axis(key, axis=0)\n        self._getitem_axis = <bound method _iLocIndexer._getitem_axis of <pandas.core.indexing._iLocIndexer object>>\n        key = memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999])\n   1329 \n   1330     def _is_scalar_access(self, key):\n   1331         raise NotImplementedError()\n   1332 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self=<pandas.core.indexing._iLocIndexer object>, key=memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999]), axis=0)\n   1733             self._has_valid_type(key, axis)\n   1734             return self._getbool_axis(key, axis=axis)\n   1735 \n   1736         # a list of integers\n   1737         elif is_list_like_indexer(key):\n-> 1738             return self._get_list_axis(key, axis=axis)\n        self._get_list_axis = <bound method _iLocIndexer._get_list_axis of <pandas.core.indexing._iLocIndexer object>>\n        key = memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999])\n        axis = 0\n   1739 \n   1740         # a single integer\n   1741         else:\n   1742             key = self._convert_scalar_indexer(key, axis)\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/indexing.py in _get_list_axis(self=<pandas.core.indexing._iLocIndexer object>, key=memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999]), axis=0)\n   1710         Returns\n   1711         -------\n   1712         Series object\n   1713         \"\"\"\n   1714         try:\n-> 1715             return self.obj.take(key, axis=axis, convert=False)\n        self.obj.take = <bound method NDFrame.take of               x1  ...49 -0.190363        a\n\n[200000 rows x 6 columns]>\n        key = memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999])\n        axis = 0\n   1716         except IndexError:\n   1717             # re-raise with different error message\n   1718             raise IndexError(\"positional indexers are out-of-bounds\")\n   1719 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/generic.py in take(self=              x1        x2        x3        x4  ...849 -0.190363        a\n\n[200000 rows x 6 columns], indices=memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999]), axis=0, convert=False, is_copy=True, **kwargs={})\n   1923         \"\"\"\n   1924         nv.validate_take(tuple(), kwargs)\n   1925         self._consolidate_inplace()\n   1926         new_data = self._data.take(indices,\n   1927                                    axis=self._get_block_manager_axis(axis),\n-> 1928                                    convert=True, verify=True)\n        convert = False\n   1929         result = self._constructor(new_data).__finalize__(self)\n   1930 \n   1931         # maybe set copy if we didn't actually change the index\n   1932         if is_copy:\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py in take(self=BlockManager\nItems: Index(['x1', 'x2', 'x3', 'x4...tBlock: slice(5, 6, 1), 1 x 200000, dtype: object, indexer=memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999]), axis=1, verify=True, convert=True)\n   4006                 raise Exception('Indices must be nonzero and less than '\n   4007                                 'the axis length')\n   4008 \n   4009         new_labels = self.axes[axis].take(indexer)\n   4010         return self.reindex_indexer(new_axis=new_labels, indexer=indexer,\n-> 4011                                     axis=axis, allow_dups=True)\n        axis = 1\n   4012 \n   4013     def merge(self, other, lsuffix='', rsuffix=''):\n   4014         if not self._is_indexed_like(other):\n   4015             raise AssertionError('Must have same axes to merge managers')\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py in reindex_indexer(self=BlockManager\nItems: Index(['x1', 'x2', 'x3', 'x4...tBlock: slice(5, 6, 1), 1 x 200000, dtype: object, new_axis=Int64Index([ 39890,  39891,  39892,  39893,  398...199999],\n           dtype='int64', length=159999), indexer=memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999]), axis=1, fill_value=None, allow_dups=True, copy=True)\n   3892             new_blocks = self._slice_take_blocks_ax0(indexer,\n   3893                                                      fill_tuple=(fill_value,))\n   3894         else:\n   3895             new_blocks = [blk.take_nd(indexer, axis=axis, fill_tuple=(\n   3896                 fill_value if fill_value is not None else blk.fill_value,))\n-> 3897                 for blk in self.blocks]\n        self.blocks = (FloatBlock: slice(0, 5, 1), 5 x 200000, dtype: float64, ObjectBlock: slice(5, 6, 1), 1 x 200000, dtype: object)\n   3898 \n   3899         new_axes = list(self.axes)\n   3900         new_axes[axis] = new_axis\n   3901         return self.__class__(new_blocks, new_axes)\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py in <listcomp>(.0=<tuple_iterator object>)\n   3892             new_blocks = self._slice_take_blocks_ax0(indexer,\n   3893                                                      fill_tuple=(fill_value,))\n   3894         else:\n   3895             new_blocks = [blk.take_nd(indexer, axis=axis, fill_tuple=(\n   3896                 fill_value if fill_value is not None else blk.fill_value,))\n-> 3897                 for blk in self.blocks]\n        blk = FloatBlock: slice(0, 5, 1), 5 x 200000, dtype: float64\n   3898 \n   3899         new_axes = list(self.axes)\n   3900         new_axes[axis] = new_axis\n   3901         return self.__class__(new_blocks, new_axes)\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py in take_nd(self=FloatBlock: slice(0, 5, 1), 5 x 200000, dtype: float64, indexer=memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999]), axis=1, new_mgr_locs=None, fill_tuple=(nan,))\n   1041             new_values = algos.take_nd(values, indexer, axis=axis,\n   1042                                        allow_fill=False)\n   1043         else:\n   1044             fill_value = fill_tuple[0]\n   1045             new_values = algos.take_nd(values, indexer, axis=axis,\n-> 1046                                        allow_fill=True, fill_value=fill_value)\n        fill_value = nan\n   1047 \n   1048         if new_mgr_locs is None:\n   1049             if axis == 0:\n   1050                 slc = lib.indexer_as_slice(indexer)\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/algorithms.py in take_nd(arr=memmap([[-0.26666035, -0.23195333, -1.14554448, ... 0.064569  ,\n         -0.07119485, -0.1903627 ]]), indexer=memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999]), axis=1, out=array([[-0.70387825,  0.01771368, -0.14068663, ....  1.11458733,\n         1.00384929, -0.1903627 ]]), fill_value=nan, mask_info=None, allow_fill=True)\n   1466         else:\n   1467             out = np.empty(out_shape, dtype=dtype)\n   1468 \n   1469     func = _get_take_nd_function(arr.ndim, arr.dtype, out.dtype, axis=axis,\n   1470                                  mask_info=mask_info)\n-> 1471     func(arr, indexer, out, fill_value)\n        func = <built-in function take_2d_axis1_float64_float64>\n        arr = memmap([[-0.26666035, -0.23195333, -1.14554448, ... 0.064569  ,\n         -0.07119485, -0.1903627 ]])\n        indexer = memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999])\n        out = array([[-0.70387825,  0.01771368, -0.14068663, ....  1.11458733,\n         1.00384929, -0.1903627 ]])\n        fill_value = nan\n   1472 \n   1473     if flip_order:\n   1474         out = out.T\n   1475     return out\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/_libs/algos.cpython-36m-darwin.so in pandas._libs.algos.take_2d_axis1_float64_float64 (pandas/_libs/algos.c:111160)()\n   4629 \n   4630 \n   4631 \n   4632 \n   4633 \n-> 4634 \n   4635 \n   4636 \n   4637 \n   4638 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/_libs/algos.cpython-36m-darwin.so in View.MemoryView.memoryview_cwrapper (pandas/_libs/algos.c:124730)()\n    639 \n    640 \n    641 \n    642 \n    643 \n--> 644 \n    645 \n    646 \n    647 \n    648 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/_libs/algos.cpython-36m-darwin.so in View.MemoryView.memoryview.__cinit__ (pandas/_libs/algos.c:120965)()\n    340 \n    341 \n    342 \n    343 \n    344 \n--> 345 \n    346 \n    347 \n    348 \n    349 \n\nValueError: buffer source array is read-only\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    681\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m'timeout'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetfullargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Wed Aug  2 18:25:00 2017\nPID: 35261Python 3.6.1: /Users/gstoddard/anaconda/envs/standard_py3_env/bin/python\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('feature_encoder', DataFrame_En...None,\n            verbose=0, warm_start=False))]),               x1        x2        x3        x4  ...849 -0.190363        a\n\n[200000 rows x 6 columns], memmap([0, 0, 1, ..., 1, 0, 1]), <function _passthrough_scorer>, memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999]), array([    0,     1,     2, ..., 40133, 40138, 40141]), 1, {'clf__n_estimators': 10}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('feature_encoder', DataFrame_En...None,\n            verbose=0, warm_start=False))]),               x1        x2        x3        x4  ...849 -0.190363        a\n\n[200000 rows x 6 columns], memmap([0, 0, 1, ..., 1, 0, 1]), <function _passthrough_scorer>, memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999]), array([    0,     1,     2, ..., 40133, 40138, 40141]), 1, {'clf__n_estimators': 10})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('feature_encoder', DataFrame_En...None,\n            verbose=0, warm_start=False))]), X=              x1        x2        x3        x4  ...849 -0.190363        a\n\n[200000 rows x 6 columns], y=memmap([0, 0, 1, ..., 1, 0, 1]), scorer=<function _passthrough_scorer>, train=memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999]), test=array([    0,     1,     2, ..., 40133, 40138, 40141]), verbose=1, parameters={'clf__n_estimators': 10}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    226     if parameters is not None:\n    227         estimator.set_params(**parameters)\n    228 \n    229     start_time = time.time()\n    230 \n--> 231     X_train, y_train = _safe_split(estimator, X, y, train)\n        X_train = undefined\n        y_train = undefined\n        estimator = Pipeline(steps=[('feature_encoder', DataFrame_En...None,\n            verbose=0, warm_start=False))])\n        X =               x1        x2        x3        x4  ...849 -0.190363        a\n\n[200000 rows x 6 columns]\n        y = memmap([0, 0, 1, ..., 1, 0, 1])\n        train = memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999])\n    232     X_test, y_test = _safe_split(estimator, X, y, test, train)\n    233 \n    234     try:\n    235         if y_train is None:\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/utils/metaestimators.py in _safe_split(estimator=Pipeline(steps=[('feature_encoder', DataFrame_En...None,\n            verbose=0, warm_start=False))]), X=              x1        x2        x3        x4  ...849 -0.190363        a\n\n[200000 rows x 6 columns], y=memmap([0, 0, 1, ..., 1, 0, 1]), indices=memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999]), train_indices=None)\n    103             if train_indices is None:\n    104                 X_subset = X[np.ix_(indices, indices)]\n    105             else:\n    106                 X_subset = X[np.ix_(indices, train_indices)]\n    107         else:\n--> 108             X_subset = safe_indexing(X, indices)\n        X_subset = undefined\n        X =               x1        x2        x3        x4  ...849 -0.190363        a\n\n[200000 rows x 6 columns]\n        indices = memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999])\n    109 \n    110     if y is not None:\n    111         y_subset = safe_indexing(y, indices)\n    112     else:\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/utils/__init__.py in safe_indexing(X=              x1        x2        x3        x4  ...849 -0.190363        a\n\n[200000 rows x 6 columns], indices=memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999]))\n    100         except ValueError:\n    101             # Cython typed memoryviews internally used in pandas do not support\n    102             # readonly buffers.\n    103             warnings.warn(\"Copying input dataframe for slicing.\",\n    104                           DataConversionWarning)\n--> 105             return X.copy().iloc[indices]\n        X.copy.iloc = undefined\n        indices = memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999])\n    106     elif hasattr(X, \"shape\"):\n    107         if hasattr(X, 'take') and (hasattr(indices, 'dtype') and\n    108                                    indices.dtype.kind == 'i'):\n    109             # This is often substantially faster than X[indices]\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self=<pandas.core.indexing._iLocIndexer object>, key=memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999]))\n   1323             except (KeyError, IndexError):\n   1324                 pass\n   1325             return self._getitem_tuple(key)\n   1326         else:\n   1327             key = com._apply_if_callable(key, self.obj)\n-> 1328             return self._getitem_axis(key, axis=0)\n        self._getitem_axis = <bound method _iLocIndexer._getitem_axis of <pandas.core.indexing._iLocIndexer object>>\n        key = memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999])\n   1329 \n   1330     def _is_scalar_access(self, key):\n   1331         raise NotImplementedError()\n   1332 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self=<pandas.core.indexing._iLocIndexer object>, key=memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999]), axis=0)\n   1733             self._has_valid_type(key, axis)\n   1734             return self._getbool_axis(key, axis=axis)\n   1735 \n   1736         # a list of integers\n   1737         elif is_list_like_indexer(key):\n-> 1738             return self._get_list_axis(key, axis=axis)\n        self._get_list_axis = <bound method _iLocIndexer._get_list_axis of <pandas.core.indexing._iLocIndexer object>>\n        key = memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999])\n        axis = 0\n   1739 \n   1740         # a single integer\n   1741         else:\n   1742             key = self._convert_scalar_indexer(key, axis)\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/indexing.py in _get_list_axis(self=<pandas.core.indexing._iLocIndexer object>, key=memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999]), axis=0)\n   1710         Returns\n   1711         -------\n   1712         Series object\n   1713         \"\"\"\n   1714         try:\n-> 1715             return self.obj.take(key, axis=axis, convert=False)\n        self.obj.take = <bound method NDFrame.take of               x1  ...49 -0.190363        a\n\n[200000 rows x 6 columns]>\n        key = memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999])\n        axis = 0\n   1716         except IndexError:\n   1717             # re-raise with different error message\n   1718             raise IndexError(\"positional indexers are out-of-bounds\")\n   1719 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/generic.py in take(self=              x1        x2        x3        x4  ...849 -0.190363        a\n\n[200000 rows x 6 columns], indices=memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999]), axis=0, convert=False, is_copy=True, **kwargs={})\n   1923         \"\"\"\n   1924         nv.validate_take(tuple(), kwargs)\n   1925         self._consolidate_inplace()\n   1926         new_data = self._data.take(indices,\n   1927                                    axis=self._get_block_manager_axis(axis),\n-> 1928                                    convert=True, verify=True)\n        convert = False\n   1929         result = self._constructor(new_data).__finalize__(self)\n   1930 \n   1931         # maybe set copy if we didn't actually change the index\n   1932         if is_copy:\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py in take(self=BlockManager\nItems: Index(['x1', 'x2', 'x3', 'x4...tBlock: slice(5, 6, 1), 1 x 200000, dtype: object, indexer=memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999]), axis=1, verify=True, convert=True)\n   4006                 raise Exception('Indices must be nonzero and less than '\n   4007                                 'the axis length')\n   4008 \n   4009         new_labels = self.axes[axis].take(indexer)\n   4010         return self.reindex_indexer(new_axis=new_labels, indexer=indexer,\n-> 4011                                     axis=axis, allow_dups=True)\n        axis = 1\n   4012 \n   4013     def merge(self, other, lsuffix='', rsuffix=''):\n   4014         if not self._is_indexed_like(other):\n   4015             raise AssertionError('Must have same axes to merge managers')\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py in reindex_indexer(self=BlockManager\nItems: Index(['x1', 'x2', 'x3', 'x4...tBlock: slice(5, 6, 1), 1 x 200000, dtype: object, new_axis=Int64Index([ 39890,  39891,  39892,  39893,  398...199999],\n           dtype='int64', length=159999), indexer=memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999]), axis=1, fill_value=None, allow_dups=True, copy=True)\n   3892             new_blocks = self._slice_take_blocks_ax0(indexer,\n   3893                                                      fill_tuple=(fill_value,))\n   3894         else:\n   3895             new_blocks = [blk.take_nd(indexer, axis=axis, fill_tuple=(\n   3896                 fill_value if fill_value is not None else blk.fill_value,))\n-> 3897                 for blk in self.blocks]\n        self.blocks = (FloatBlock: slice(0, 5, 1), 5 x 200000, dtype: float64, ObjectBlock: slice(5, 6, 1), 1 x 200000, dtype: object)\n   3898 \n   3899         new_axes = list(self.axes)\n   3900         new_axes[axis] = new_axis\n   3901         return self.__class__(new_blocks, new_axes)\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py in <listcomp>(.0=<tuple_iterator object>)\n   3892             new_blocks = self._slice_take_blocks_ax0(indexer,\n   3893                                                      fill_tuple=(fill_value,))\n   3894         else:\n   3895             new_blocks = [blk.take_nd(indexer, axis=axis, fill_tuple=(\n   3896                 fill_value if fill_value is not None else blk.fill_value,))\n-> 3897                 for blk in self.blocks]\n        blk = FloatBlock: slice(0, 5, 1), 5 x 200000, dtype: float64\n   3898 \n   3899         new_axes = list(self.axes)\n   3900         new_axes[axis] = new_axis\n   3901         return self.__class__(new_blocks, new_axes)\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py in take_nd(self=FloatBlock: slice(0, 5, 1), 5 x 200000, dtype: float64, indexer=memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999]), axis=1, new_mgr_locs=None, fill_tuple=(nan,))\n   1041             new_values = algos.take_nd(values, indexer, axis=axis,\n   1042                                        allow_fill=False)\n   1043         else:\n   1044             fill_value = fill_tuple[0]\n   1045             new_values = algos.take_nd(values, indexer, axis=axis,\n-> 1046                                        allow_fill=True, fill_value=fill_value)\n        fill_value = nan\n   1047 \n   1048         if new_mgr_locs is None:\n   1049             if axis == 0:\n   1050                 slc = lib.indexer_as_slice(indexer)\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/algorithms.py in take_nd(arr=memmap([[-0.26666035, -0.23195333, -1.14554448, ... 0.064569  ,\n         -0.07119485, -0.1903627 ]]), indexer=memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999]), axis=1, out=array([[-0.70387825,  0.01771368, -0.14068663, ....  1.11458733,\n         1.00384929, -0.1903627 ]]), fill_value=nan, mask_info=None, allow_fill=True)\n   1466         else:\n   1467             out = np.empty(out_shape, dtype=dtype)\n   1468 \n   1469     func = _get_take_nd_function(arr.ndim, arr.dtype, out.dtype, axis=axis,\n   1470                                  mask_info=mask_info)\n-> 1471     func(arr, indexer, out, fill_value)\n        func = <built-in function take_2d_axis1_float64_float64>\n        arr = memmap([[-0.26666035, -0.23195333, -1.14554448, ... 0.064569  ,\n         -0.07119485, -0.1903627 ]])\n        indexer = memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999])\n        out = array([[-0.70387825,  0.01771368, -0.14068663, ....  1.11458733,\n         1.00384929, -0.1903627 ]])\n        fill_value = nan\n   1472 \n   1473     if flip_order:\n   1474         out = out.T\n   1475     return out\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/_libs/algos.cpython-36m-darwin.so in pandas._libs.algos.take_2d_axis1_float64_float64 (pandas/_libs/algos.c:111160)()\n   4629 \n   4630 \n   4631 \n   4632 \n   4633 \n-> 4634 \n   4635 \n   4636 \n   4637 \n   4638 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/_libs/algos.cpython-36m-darwin.so in View.MemoryView.memoryview_cwrapper (pandas/_libs/algos.c:124730)()\n    639 \n    640 \n    641 \n    642 \n    643 \n--> 644 \n    645 \n    646 \n    647 \n    648 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/_libs/algos.cpython-36m-darwin.so in View.MemoryView.memoryview.__cinit__ (pandas/_libs/algos.c:120965)()\n    340 \n    341 \n    342 \n    343 \n    344 \n--> 345 \n    346 \n    347 \n    348 \n    349 \n\nValueError: buffer source array is read-only\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b63d72744ba1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtest\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \"\"\"\n\u001b[0;32m--> 945\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                   \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m--> 564\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m           for train, test in cv_iter)\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x10e8bd030, file \"/Use...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/Users/gstoddard/anaconda/envs/standard_py3_env/...ges/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/Users/gstod.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x10e8bd030, file \"/Use...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/Users/gstoddard/anaconda/envs/standard_py3_env/...ges/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/Users/gstod.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n     17 \n     18 \n     19 \n     20 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 5\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 5), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 5)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=5)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'x,y = make_classification(n_samples=200000,n_fea...ram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 8, 2, 22, 24, 59, 88163, tzinfo=tzutc()), 'msg_id': '81F1F7C9D6BE4AB79A8ED2592D8F62FE', 'msg_type': 'execute_request', 'session': 'A09FD675E3EA46CB837CBE1D3E75F32E', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '81F1F7C9D6BE4AB79A8ED2592D8F62FE', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'A09FD675E3EA46CB837CBE1D3E75F32E']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'x,y = make_classification(n_samples=200000,n_fea...ram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 8, 2, 22, 24, 59, 88163, tzinfo=tzutc()), 'msg_id': '81F1F7C9D6BE4AB79A8ED2592D8F62FE', 'msg_type': 'execute_request', 'session': 'A09FD675E3EA46CB837CBE1D3E75F32E', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '81F1F7C9D6BE4AB79A8ED2592D8F62FE', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'A09FD675E3EA46CB837CBE1D3E75F32E'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'x,y = make_classification(n_samples=200000,n_fea...ram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 8, 2, 22, 24, 59, 88163, tzinfo=tzutc()), 'msg_id': '81F1F7C9D6BE4AB79A8ED2592D8F62FE', 'msg_type': 'execute_request', 'session': 'A09FD675E3EA46CB837CBE1D3E75F32E', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '81F1F7C9D6BE4AB79A8ED2592D8F62FE', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='x,y = make_classification(n_samples=200000,n_fea...ram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)\\n', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'x,y = make_classification(n_samples=200000,n_fea...ram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)\\n'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('x,y = make_classification(n_samples=200000,n_fea...ram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)\\n',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('x,y = make_classification(n_samples=200000,n_fea...ram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)\\n',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='x,y = make_classification(n_samples=200000,n_fea...ram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)\\n', store_history=True, silent=False, shell_futures=True)\n   2678                 self.displayhook.exec_result = result\n   2679 \n   2680                 # Execute the user code\n   2681                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2682                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2683                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2684                 \n   2685                 self.last_execution_succeeded = not has_raised\n   2686 \n   2687                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-3-b63d72744ba1>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 119404c50, execution_..._before_exec=None error_in_exec=None result=None>)\n   2788                     return True\n   2789 \n   2790             for i, node in enumerate(to_run_interactive):\n   2791                 mod = ast.Interactive([node])\n   2792                 code = compiler(mod, cell_name, \"single\")\n-> 2793                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x1193a4f60, file \"<ipython-input-3-b63d72744ba1>\", line 20>\n        result = <ExecutionResult object at 119404c50, execution_..._before_exec=None error_in_exec=None result=None>\n   2794                     return True\n   2795 \n   2796             # Flush softspace\n   2797             if softspace(sys.stdout, 0):\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x1193a4f60, file \"<ipython-input-3-b63d72744ba1>\", line 20>, result=<ExecutionResult object at 119404c50, execution_..._before_exec=None error_in_exec=None result=None>)\n   2842         outflag = True  # happens in more places, so it's easier as default\n   2843         try:\n   2844             try:\n   2845                 self.hooks.pre_run_code_hook()\n   2846                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2847                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x1193a4f60, file \"<ipython-input-3-b63d72744ba1>\", line 20>\n        self.user_global_ns = {'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'DataFrame_Encoder': <class '__main__.DataFrame_Encoder'>, 'DictVectorizer': <class 'sklearn.feature_extraction.dict_vectorizer.DictVectorizer'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import pandas as pd\\n\\nfrom sklearn.model_selectio...raction import DictVectorizer\\n\\nimport numpy as np', 'class DataFrame_Encoder(BaseEstimator, Transform..., categorical_df],axis=1)\\n        return new_data', 'x,y = make_classification(n_samples=200000,n_fea...aram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)'], 'Out': {}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'TransformerMixin': <class 'sklearn.base.TransformerMixin'>, '_': '', ...}\n        self.user_ns = {'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'DataFrame_Encoder': <class '__main__.DataFrame_Encoder'>, 'DictVectorizer': <class 'sklearn.feature_extraction.dict_vectorizer.DictVectorizer'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import pandas as pd\\n\\nfrom sklearn.model_selectio...raction import DictVectorizer\\n\\nimport numpy as np', 'class DataFrame_Encoder(BaseEstimator, Transform..., categorical_df],axis=1)\\n        return new_data', 'x,y = make_classification(n_samples=200000,n_fea...aram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)'], 'Out': {}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'TransformerMixin': <class 'sklearn.base.TransformerMixin'>, '_': '', ...}\n   2848             finally:\n   2849                 # Reset our crash handler in place\n   2850                 sys.excepthook = old_excepthook\n   2851         except SystemExit as e:\n\n...........................................................................\n/Users/gstoddard/sklearn_bug/<ipython-input-3-b63d72744ba1> in <module>()\n     15 ])\n     16 pipeline.set_params(feature_encoder__categorical_cols_=string_features, feature_encoder__numeric_cols_=numeric_features)\n     17 \n     18 clf = GridSearchCV(pipeline, param_grid,cv=5,n_jobs=2,verbose=1)\n     19 \n---> 20 clf.fit(df,y)\n     21 \n     22 \n     23 \n     24 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...train_score=True,\n       scoring=None, verbose=1), X=              x1        x2        x3        x4  ...849 -0.190363        a\n\n[200000 rows x 6 columns], y=array([0, 0, 1, ..., 1, 0, 1]), groups=None)\n    940 \n    941         groups : array-like, with shape (n_samples,), optional\n    942             Group labels for the samples used while splitting the dataset into\n    943             train/test set.\n    944         \"\"\"\n--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))\n        self._fit = <bound method BaseSearchCV._fit of GridSearchCV(...rain_score=True,\n       scoring=None, verbose=1)>\n        X =               x1        x2        x3        x4  ...849 -0.190363        a\n\n[200000 rows x 6 columns]\n        y = array([0, 0, 1, ..., 1, 0, 1])\n        groups = None\n        self.param_grid = {'clf__n_estimators': [10, 100]}\n    946 \n    947 \n    948 class RandomizedSearchCV(BaseSearchCV):\n    949     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...train_score=True,\n       scoring=None, verbose=1), X=              x1        x2        x3        x4  ...849 -0.190363        a\n\n[200000 rows x 6 columns], y=array([0, 0, 1, ..., 1, 0, 1]), groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)\n    559                                   fit_params=self.fit_params,\n    560                                   return_train_score=self.return_train_score,\n    561                                   return_n_test_samples=True,\n    562                                   return_times=True, return_parameters=True,\n    563                                   error_score=self.error_score)\n--> 564           for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>\n    565           for train, test in cv_iter)\n    566 \n    567         # if one choose to see train score, \"out\" will contain train score info\n    568         if self.return_train_score:\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=2), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=2)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Wed Aug  2 18:25:00 2017\nPID: 35261Python 3.6.1: /Users/gstoddard/anaconda/envs/standard_py3_env/bin/python\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('feature_encoder', DataFrame_En...None,\n            verbose=0, warm_start=False))]),               x1        x2        x3        x4  ...849 -0.190363        a\n\n[200000 rows x 6 columns], memmap([0, 0, 1, ..., 1, 0, 1]), <function _passthrough_scorer>, memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999]), array([    0,     1,     2, ..., 40133, 40138, 40141]), 1, {'clf__n_estimators': 10}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('feature_encoder', DataFrame_En...None,\n            verbose=0, warm_start=False))]),               x1        x2        x3        x4  ...849 -0.190363        a\n\n[200000 rows x 6 columns], memmap([0, 0, 1, ..., 1, 0, 1]), <function _passthrough_scorer>, memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999]), array([    0,     1,     2, ..., 40133, 40138, 40141]), 1, {'clf__n_estimators': 10})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('feature_encoder', DataFrame_En...None,\n            verbose=0, warm_start=False))]), X=              x1        x2        x3        x4  ...849 -0.190363        a\n\n[200000 rows x 6 columns], y=memmap([0, 0, 1, ..., 1, 0, 1]), scorer=<function _passthrough_scorer>, train=memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999]), test=array([    0,     1,     2, ..., 40133, 40138, 40141]), verbose=1, parameters={'clf__n_estimators': 10}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    226     if parameters is not None:\n    227         estimator.set_params(**parameters)\n    228 \n    229     start_time = time.time()\n    230 \n--> 231     X_train, y_train = _safe_split(estimator, X, y, train)\n        X_train = undefined\n        y_train = undefined\n        estimator = Pipeline(steps=[('feature_encoder', DataFrame_En...None,\n            verbose=0, warm_start=False))])\n        X =               x1        x2        x3        x4  ...849 -0.190363        a\n\n[200000 rows x 6 columns]\n        y = memmap([0, 0, 1, ..., 1, 0, 1])\n        train = memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999])\n    232     X_test, y_test = _safe_split(estimator, X, y, test, train)\n    233 \n    234     try:\n    235         if y_train is None:\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/utils/metaestimators.py in _safe_split(estimator=Pipeline(steps=[('feature_encoder', DataFrame_En...None,\n            verbose=0, warm_start=False))]), X=              x1        x2        x3        x4  ...849 -0.190363        a\n\n[200000 rows x 6 columns], y=memmap([0, 0, 1, ..., 1, 0, 1]), indices=memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999]), train_indices=None)\n    103             if train_indices is None:\n    104                 X_subset = X[np.ix_(indices, indices)]\n    105             else:\n    106                 X_subset = X[np.ix_(indices, train_indices)]\n    107         else:\n--> 108             X_subset = safe_indexing(X, indices)\n        X_subset = undefined\n        X =               x1        x2        x3        x4  ...849 -0.190363        a\n\n[200000 rows x 6 columns]\n        indices = memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999])\n    109 \n    110     if y is not None:\n    111         y_subset = safe_indexing(y, indices)\n    112     else:\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/utils/__init__.py in safe_indexing(X=              x1        x2        x3        x4  ...849 -0.190363        a\n\n[200000 rows x 6 columns], indices=memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999]))\n    100         except ValueError:\n    101             # Cython typed memoryviews internally used in pandas do not support\n    102             # readonly buffers.\n    103             warnings.warn(\"Copying input dataframe for slicing.\",\n    104                           DataConversionWarning)\n--> 105             return X.copy().iloc[indices]\n        X.copy.iloc = undefined\n        indices = memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999])\n    106     elif hasattr(X, \"shape\"):\n    107         if hasattr(X, 'take') and (hasattr(indices, 'dtype') and\n    108                                    indices.dtype.kind == 'i'):\n    109             # This is often substantially faster than X[indices]\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self=<pandas.core.indexing._iLocIndexer object>, key=memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999]))\n   1323             except (KeyError, IndexError):\n   1324                 pass\n   1325             return self._getitem_tuple(key)\n   1326         else:\n   1327             key = com._apply_if_callable(key, self.obj)\n-> 1328             return self._getitem_axis(key, axis=0)\n        self._getitem_axis = <bound method _iLocIndexer._getitem_axis of <pandas.core.indexing._iLocIndexer object>>\n        key = memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999])\n   1329 \n   1330     def _is_scalar_access(self, key):\n   1331         raise NotImplementedError()\n   1332 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self=<pandas.core.indexing._iLocIndexer object>, key=memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999]), axis=0)\n   1733             self._has_valid_type(key, axis)\n   1734             return self._getbool_axis(key, axis=axis)\n   1735 \n   1736         # a list of integers\n   1737         elif is_list_like_indexer(key):\n-> 1738             return self._get_list_axis(key, axis=axis)\n        self._get_list_axis = <bound method _iLocIndexer._get_list_axis of <pandas.core.indexing._iLocIndexer object>>\n        key = memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999])\n        axis = 0\n   1739 \n   1740         # a single integer\n   1741         else:\n   1742             key = self._convert_scalar_indexer(key, axis)\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/indexing.py in _get_list_axis(self=<pandas.core.indexing._iLocIndexer object>, key=memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999]), axis=0)\n   1710         Returns\n   1711         -------\n   1712         Series object\n   1713         \"\"\"\n   1714         try:\n-> 1715             return self.obj.take(key, axis=axis, convert=False)\n        self.obj.take = <bound method NDFrame.take of               x1  ...49 -0.190363        a\n\n[200000 rows x 6 columns]>\n        key = memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999])\n        axis = 0\n   1716         except IndexError:\n   1717             # re-raise with different error message\n   1718             raise IndexError(\"positional indexers are out-of-bounds\")\n   1719 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/generic.py in take(self=              x1        x2        x3        x4  ...849 -0.190363        a\n\n[200000 rows x 6 columns], indices=memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999]), axis=0, convert=False, is_copy=True, **kwargs={})\n   1923         \"\"\"\n   1924         nv.validate_take(tuple(), kwargs)\n   1925         self._consolidate_inplace()\n   1926         new_data = self._data.take(indices,\n   1927                                    axis=self._get_block_manager_axis(axis),\n-> 1928                                    convert=True, verify=True)\n        convert = False\n   1929         result = self._constructor(new_data).__finalize__(self)\n   1930 \n   1931         # maybe set copy if we didn't actually change the index\n   1932         if is_copy:\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py in take(self=BlockManager\nItems: Index(['x1', 'x2', 'x3', 'x4...tBlock: slice(5, 6, 1), 1 x 200000, dtype: object, indexer=memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999]), axis=1, verify=True, convert=True)\n   4006                 raise Exception('Indices must be nonzero and less than '\n   4007                                 'the axis length')\n   4008 \n   4009         new_labels = self.axes[axis].take(indexer)\n   4010         return self.reindex_indexer(new_axis=new_labels, indexer=indexer,\n-> 4011                                     axis=axis, allow_dups=True)\n        axis = 1\n   4012 \n   4013     def merge(self, other, lsuffix='', rsuffix=''):\n   4014         if not self._is_indexed_like(other):\n   4015             raise AssertionError('Must have same axes to merge managers')\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py in reindex_indexer(self=BlockManager\nItems: Index(['x1', 'x2', 'x3', 'x4...tBlock: slice(5, 6, 1), 1 x 200000, dtype: object, new_axis=Int64Index([ 39890,  39891,  39892,  39893,  398...199999],\n           dtype='int64', length=159999), indexer=memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999]), axis=1, fill_value=None, allow_dups=True, copy=True)\n   3892             new_blocks = self._slice_take_blocks_ax0(indexer,\n   3893                                                      fill_tuple=(fill_value,))\n   3894         else:\n   3895             new_blocks = [blk.take_nd(indexer, axis=axis, fill_tuple=(\n   3896                 fill_value if fill_value is not None else blk.fill_value,))\n-> 3897                 for blk in self.blocks]\n        self.blocks = (FloatBlock: slice(0, 5, 1), 5 x 200000, dtype: float64, ObjectBlock: slice(5, 6, 1), 1 x 200000, dtype: object)\n   3898 \n   3899         new_axes = list(self.axes)\n   3900         new_axes[axis] = new_axis\n   3901         return self.__class__(new_blocks, new_axes)\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py in <listcomp>(.0=<tuple_iterator object>)\n   3892             new_blocks = self._slice_take_blocks_ax0(indexer,\n   3893                                                      fill_tuple=(fill_value,))\n   3894         else:\n   3895             new_blocks = [blk.take_nd(indexer, axis=axis, fill_tuple=(\n   3896                 fill_value if fill_value is not None else blk.fill_value,))\n-> 3897                 for blk in self.blocks]\n        blk = FloatBlock: slice(0, 5, 1), 5 x 200000, dtype: float64\n   3898 \n   3899         new_axes = list(self.axes)\n   3900         new_axes[axis] = new_axis\n   3901         return self.__class__(new_blocks, new_axes)\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py in take_nd(self=FloatBlock: slice(0, 5, 1), 5 x 200000, dtype: float64, indexer=memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999]), axis=1, new_mgr_locs=None, fill_tuple=(nan,))\n   1041             new_values = algos.take_nd(values, indexer, axis=axis,\n   1042                                        allow_fill=False)\n   1043         else:\n   1044             fill_value = fill_tuple[0]\n   1045             new_values = algos.take_nd(values, indexer, axis=axis,\n-> 1046                                        allow_fill=True, fill_value=fill_value)\n        fill_value = nan\n   1047 \n   1048         if new_mgr_locs is None:\n   1049             if axis == 0:\n   1050                 slc = lib.indexer_as_slice(indexer)\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/algorithms.py in take_nd(arr=memmap([[-0.26666035, -0.23195333, -1.14554448, ... 0.064569  ,\n         -0.07119485, -0.1903627 ]]), indexer=memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999]), axis=1, out=array([[-0.70387825,  0.01771368, -0.14068663, ....  1.11458733,\n         1.00384929, -0.1903627 ]]), fill_value=nan, mask_info=None, allow_fill=True)\n   1466         else:\n   1467             out = np.empty(out_shape, dtype=dtype)\n   1468 \n   1469     func = _get_take_nd_function(arr.ndim, arr.dtype, out.dtype, axis=axis,\n   1470                                  mask_info=mask_info)\n-> 1471     func(arr, indexer, out, fill_value)\n        func = <built-in function take_2d_axis1_float64_float64>\n        arr = memmap([[-0.26666035, -0.23195333, -1.14554448, ... 0.064569  ,\n         -0.07119485, -0.1903627 ]])\n        indexer = memmap([ 39890,  39891,  39892, ..., 199997, 199998, 199999])\n        out = array([[-0.70387825,  0.01771368, -0.14068663, ....  1.11458733,\n         1.00384929, -0.1903627 ]])\n        fill_value = nan\n   1472 \n   1473     if flip_order:\n   1474         out = out.T\n   1475     return out\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/_libs/algos.cpython-36m-darwin.so in pandas._libs.algos.take_2d_axis1_float64_float64 (pandas/_libs/algos.c:111160)()\n   4629 \n   4630 \n   4631 \n   4632 \n   4633 \n-> 4634 \n   4635 \n   4636 \n   4637 \n   4638 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/_libs/algos.cpython-36m-darwin.so in View.MemoryView.memoryview_cwrapper (pandas/_libs/algos.c:124730)()\n    639 \n    640 \n    641 \n    642 \n    643 \n--> 644 \n    645 \n    646 \n    647 \n    648 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/_libs/algos.cpython-36m-darwin.so in View.MemoryView.memoryview.__cinit__ (pandas/_libs/algos.c:120965)()\n    340 \n    341 \n    342 \n    343 \n    344 \n--> 345 \n    346 \n    347 \n    348 \n    349 \n\nValueError: buffer source array is read-only\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "x,y = make_classification(n_samples=200000,n_features=5)\n",
    "\n",
    "numeric_features = ['x1','x2','x3','x4','x5']\n",
    "string_features = ['category']\n",
    "\n",
    "df = pd.DataFrame(data=x,columns=numeric_features)\n",
    "df['category'] = 'a'\n",
    "\n",
    "base_clf = RandomForestClassifier(n_jobs=4)\n",
    "param_grid = {'clf__n_estimators':[10,100]}\n",
    "\n",
    "pipeline = Pipeline([\n",
    "        ('feature_encoder',DataFrame_Encoder()),\n",
    "        ('clf',base_clf)\n",
    "])\n",
    "pipeline.set_params(feature_encoder__categorical_cols_=string_features, feature_encoder__numeric_cols_=numeric_features)\n",
    "\n",
    "clf = GridSearchCV(pipeline, param_grid,cv=5,n_jobs=2,verbose=1)\n",
    "\n",
    "clf.fit(df,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Example 2: Fails\n",
    "\n",
    "First we attempt to get rid of the string columns (by setting the list `string_features` to be empty) and see if that fixes anything. It doesn't. Furthermore, a glance at the output shows that `fit` and `transform` are never called. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__ called\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "__init__ called\n",
      "__init__ called\n",
      "__init__ called\n",
      "__init__ called\n",
      "__init__ called\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/utils/__init__.py:104: DataConversionWarning: Copying input dataframe for slicing.\n",
      "  DataConversionWarning)\n",
      "/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/utils/__init__.py:104: DataConversionWarning: Copying input dataframe for slicing.\n",
      "  DataConversionWarning)\n",
      "/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/utils/__init__.py:104: DataConversionWarning: Copying input dataframe for slicing.\n",
      "  DataConversionWarning)\n"
     ]
    },
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x10e8bd030, file \"/Use...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/Users/gstoddard/anaconda/envs/standard_py3_env/...ges/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/Users/gstod.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x10e8bd030, file \"/Use...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/Users/gstoddard/anaconda/envs/standard_py3_env/...ges/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/Users/gstod.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n     17 \n     18 \n     19 \n     20 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'x,y = make_classification(n_samples=200000,n_fea...ram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 8, 2, 22, 31, 52, 510190, tzinfo=tzutc()), 'msg_id': 'D98F82F152284DFFA8552ADFF17725A4', 'msg_type': 'execute_request', 'session': 'A09FD675E3EA46CB837CBE1D3E75F32E', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'D98F82F152284DFFA8552ADFF17725A4', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'A09FD675E3EA46CB837CBE1D3E75F32E']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'x,y = make_classification(n_samples=200000,n_fea...ram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 8, 2, 22, 31, 52, 510190, tzinfo=tzutc()), 'msg_id': 'D98F82F152284DFFA8552ADFF17725A4', 'msg_type': 'execute_request', 'session': 'A09FD675E3EA46CB837CBE1D3E75F32E', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'D98F82F152284DFFA8552ADFF17725A4', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'A09FD675E3EA46CB837CBE1D3E75F32E'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'x,y = make_classification(n_samples=200000,n_fea...ram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 8, 2, 22, 31, 52, 510190, tzinfo=tzutc()), 'msg_id': 'D98F82F152284DFFA8552ADFF17725A4', 'msg_type': 'execute_request', 'session': 'A09FD675E3EA46CB837CBE1D3E75F32E', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'D98F82F152284DFFA8552ADFF17725A4', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='x,y = make_classification(n_samples=200000,n_fea...ram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)\\n', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'x,y = make_classification(n_samples=200000,n_fea...ram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)\\n'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('x,y = make_classification(n_samples=200000,n_fea...ram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)\\n',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('x,y = make_classification(n_samples=200000,n_fea...ram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)\\n',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='x,y = make_classification(n_samples=200000,n_fea...ram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)\\n', store_history=True, silent=False, shell_futures=True)\n   2678                 self.displayhook.exec_result = result\n   2679 \n   2680                 # Execute the user code\n   2681                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2682                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2683                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2684                 \n   2685                 self.last_execution_succeeded = not has_raised\n   2686 \n   2687                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-4-a373d1acd0e6>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 1196c4390, execution_..._before_exec=None error_in_exec=None result=None>)\n   2788                     return True\n   2789 \n   2790             for i, node in enumerate(to_run_interactive):\n   2791                 mod = ast.Interactive([node])\n   2792                 code = compiler(mod, cell_name, \"single\")\n-> 2793                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x1195a45d0, file \"<ipython-input-4-a373d1acd0e6>\", line 21>\n        result = <ExecutionResult object at 1196c4390, execution_..._before_exec=None error_in_exec=None result=None>\n   2794                     return True\n   2795 \n   2796             # Flush softspace\n   2797             if softspace(sys.stdout, 0):\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x1195a45d0, file \"<ipython-input-4-a373d1acd0e6>\", line 21>, result=<ExecutionResult object at 1196c4390, execution_..._before_exec=None error_in_exec=None result=None>)\n   2842         outflag = True  # happens in more places, so it's easier as default\n   2843         try:\n   2844             try:\n   2845                 self.hooks.pre_run_code_hook()\n   2846                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2847                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x1195a45d0, file \"<ipython-input-4-a373d1acd0e6>\", line 21>\n        self.user_global_ns = {'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'DataFrame_Encoder': <class '__main__.DataFrame_Encoder'>, 'DictVectorizer': <class 'sklearn.feature_extraction.dict_vectorizer.DictVectorizer'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import pandas as pd\\n\\nfrom sklearn.model_selectio...raction import DictVectorizer\\n\\nimport numpy as np', 'class DataFrame_Encoder(BaseEstimator, Transform..., categorical_df],axis=1)\\n        return new_data', 'x,y = make_classification(n_samples=200000,n_fea...aram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)', 'x,y = make_classification(n_samples=200000,n_fea...aram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)'], 'Out': {}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'TransformerMixin': <class 'sklearn.base.TransformerMixin'>, '_': '', ...}\n        self.user_ns = {'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'DataFrame_Encoder': <class '__main__.DataFrame_Encoder'>, 'DictVectorizer': <class 'sklearn.feature_extraction.dict_vectorizer.DictVectorizer'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import pandas as pd\\n\\nfrom sklearn.model_selectio...raction import DictVectorizer\\n\\nimport numpy as np', 'class DataFrame_Encoder(BaseEstimator, Transform..., categorical_df],axis=1)\\n        return new_data', 'x,y = make_classification(n_samples=200000,n_fea...aram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)', 'x,y = make_classification(n_samples=200000,n_fea...aram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)'], 'Out': {}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'TransformerMixin': <class 'sklearn.base.TransformerMixin'>, '_': '', ...}\n   2848             finally:\n   2849                 # Reset our crash handler in place\n   2850                 sys.excepthook = old_excepthook\n   2851         except SystemExit as e:\n\n...........................................................................\n/Users/gstoddard/sklearn_bug/<ipython-input-4-a373d1acd0e6> in <module>()\n     16 ])\n     17 pipeline.set_params(feature_encoder__categorical_cols_=string_features, feature_encoder__numeric_cols_=numeric_features)\n     18 \n     19 clf = GridSearchCV(pipeline, param_grid,cv=5,n_jobs=2,verbose=1)\n     20 \n---> 21 clf.fit(df,y)\n     22 \n     23 \n     24 \n     25 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...train_score=True,\n       scoring=None, verbose=1), X=              x1        x2        x3        x4  ...254  1.403188        a\n\n[200000 rows x 6 columns], y=array([0, 1, 0, ..., 1, 0, 1]), groups=None)\n    940 \n    941         groups : array-like, with shape (n_samples,), optional\n    942             Group labels for the samples used while splitting the dataset into\n    943             train/test set.\n    944         \"\"\"\n--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))\n        self._fit = <bound method BaseSearchCV._fit of GridSearchCV(...rain_score=True,\n       scoring=None, verbose=1)>\n        X =               x1        x2        x3        x4  ...254  1.403188        a\n\n[200000 rows x 6 columns]\n        y = array([0, 1, 0, ..., 1, 0, 1])\n        groups = None\n        self.param_grid = {'clf__n_estimators': [10, 100]}\n    946 \n    947 \n    948 class RandomizedSearchCV(BaseSearchCV):\n    949     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...train_score=True,\n       scoring=None, verbose=1), X=              x1        x2        x3        x4  ...254  1.403188        a\n\n[200000 rows x 6 columns], y=array([0, 1, 0, ..., 1, 0, 1]), groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)\n    559                                   fit_params=self.fit_params,\n    560                                   return_train_score=self.return_train_score,\n    561                                   return_n_test_samples=True,\n    562                                   return_times=True, return_parameters=True,\n    563                                   error_score=self.error_score)\n--> 564           for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>\n    565           for train, test in cv_iter)\n    566 \n    567         # if one choose to see train score, \"out\" will contain train score info\n    568         if self.return_train_score:\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=2), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=2)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Wed Aug  2 18:31:52 2017\nPID: 35368Python 3.6.1: /Users/gstoddard/anaconda/envs/standard_py3_env/bin/python\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('feature_encoder', DataFrame_En...None,\n            verbose=0, warm_start=False))]),               x1        x2        x3        x4  ...254  1.403188        a\n\n[200000 rows x 6 columns], memmap([0, 1, 0, ..., 1, 0, 1]), <function _passthrough_scorer>, memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999]), array([    0,     1,     2, ..., 40167, 40169, 40171]), 1, {'clf__n_estimators': 10}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('feature_encoder', DataFrame_En...None,\n            verbose=0, warm_start=False))]),               x1        x2        x3        x4  ...254  1.403188        a\n\n[200000 rows x 6 columns], memmap([0, 1, 0, ..., 1, 0, 1]), <function _passthrough_scorer>, memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999]), array([    0,     1,     2, ..., 40167, 40169, 40171]), 1, {'clf__n_estimators': 10})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('feature_encoder', DataFrame_En...None,\n            verbose=0, warm_start=False))]), X=              x1        x2        x3        x4  ...254  1.403188        a\n\n[200000 rows x 6 columns], y=memmap([0, 1, 0, ..., 1, 0, 1]), scorer=<function _passthrough_scorer>, train=memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999]), test=array([    0,     1,     2, ..., 40167, 40169, 40171]), verbose=1, parameters={'clf__n_estimators': 10}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    226     if parameters is not None:\n    227         estimator.set_params(**parameters)\n    228 \n    229     start_time = time.time()\n    230 \n--> 231     X_train, y_train = _safe_split(estimator, X, y, train)\n        X_train = undefined\n        y_train = undefined\n        estimator = Pipeline(steps=[('feature_encoder', DataFrame_En...None,\n            verbose=0, warm_start=False))])\n        X =               x1        x2        x3        x4  ...254  1.403188        a\n\n[200000 rows x 6 columns]\n        y = memmap([0, 1, 0, ..., 1, 0, 1])\n        train = memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999])\n    232     X_test, y_test = _safe_split(estimator, X, y, test, train)\n    233 \n    234     try:\n    235         if y_train is None:\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/utils/metaestimators.py in _safe_split(estimator=Pipeline(steps=[('feature_encoder', DataFrame_En...None,\n            verbose=0, warm_start=False))]), X=              x1        x2        x3        x4  ...254  1.403188        a\n\n[200000 rows x 6 columns], y=memmap([0, 1, 0, ..., 1, 0, 1]), indices=memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999]), train_indices=None)\n    103             if train_indices is None:\n    104                 X_subset = X[np.ix_(indices, indices)]\n    105             else:\n    106                 X_subset = X[np.ix_(indices, train_indices)]\n    107         else:\n--> 108             X_subset = safe_indexing(X, indices)\n        X_subset = undefined\n        X =               x1        x2        x3        x4  ...254  1.403188        a\n\n[200000 rows x 6 columns]\n        indices = memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999])\n    109 \n    110     if y is not None:\n    111         y_subset = safe_indexing(y, indices)\n    112     else:\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/utils/__init__.py in safe_indexing(X=              x1        x2        x3        x4  ...254  1.403188        a\n\n[200000 rows x 6 columns], indices=memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999]))\n    100         except ValueError:\n    101             # Cython typed memoryviews internally used in pandas do not support\n    102             # readonly buffers.\n    103             warnings.warn(\"Copying input dataframe for slicing.\",\n    104                           DataConversionWarning)\n--> 105             return X.copy().iloc[indices]\n        X.copy.iloc = undefined\n        indices = memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999])\n    106     elif hasattr(X, \"shape\"):\n    107         if hasattr(X, 'take') and (hasattr(indices, 'dtype') and\n    108                                    indices.dtype.kind == 'i'):\n    109             # This is often substantially faster than X[indices]\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self=<pandas.core.indexing._iLocIndexer object>, key=memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999]))\n   1323             except (KeyError, IndexError):\n   1324                 pass\n   1325             return self._getitem_tuple(key)\n   1326         else:\n   1327             key = com._apply_if_callable(key, self.obj)\n-> 1328             return self._getitem_axis(key, axis=0)\n        self._getitem_axis = <bound method _iLocIndexer._getitem_axis of <pandas.core.indexing._iLocIndexer object>>\n        key = memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999])\n   1329 \n   1330     def _is_scalar_access(self, key):\n   1331         raise NotImplementedError()\n   1332 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self=<pandas.core.indexing._iLocIndexer object>, key=memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999]), axis=0)\n   1733             self._has_valid_type(key, axis)\n   1734             return self._getbool_axis(key, axis=axis)\n   1735 \n   1736         # a list of integers\n   1737         elif is_list_like_indexer(key):\n-> 1738             return self._get_list_axis(key, axis=axis)\n        self._get_list_axis = <bound method _iLocIndexer._get_list_axis of <pandas.core.indexing._iLocIndexer object>>\n        key = memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999])\n        axis = 0\n   1739 \n   1740         # a single integer\n   1741         else:\n   1742             key = self._convert_scalar_indexer(key, axis)\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/indexing.py in _get_list_axis(self=<pandas.core.indexing._iLocIndexer object>, key=memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999]), axis=0)\n   1710         Returns\n   1711         -------\n   1712         Series object\n   1713         \"\"\"\n   1714         try:\n-> 1715             return self.obj.take(key, axis=axis, convert=False)\n        self.obj.take = <bound method NDFrame.take of               x1  ...54  1.403188        a\n\n[200000 rows x 6 columns]>\n        key = memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999])\n        axis = 0\n   1716         except IndexError:\n   1717             # re-raise with different error message\n   1718             raise IndexError(\"positional indexers are out-of-bounds\")\n   1719 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/generic.py in take(self=              x1        x2        x3        x4  ...254  1.403188        a\n\n[200000 rows x 6 columns], indices=memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999]), axis=0, convert=False, is_copy=True, **kwargs={})\n   1923         \"\"\"\n   1924         nv.validate_take(tuple(), kwargs)\n   1925         self._consolidate_inplace()\n   1926         new_data = self._data.take(indices,\n   1927                                    axis=self._get_block_manager_axis(axis),\n-> 1928                                    convert=True, verify=True)\n        convert = False\n   1929         result = self._constructor(new_data).__finalize__(self)\n   1930 \n   1931         # maybe set copy if we didn't actually change the index\n   1932         if is_copy:\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py in take(self=BlockManager\nItems: Index(['x1', 'x2', 'x3', 'x4...tBlock: slice(5, 6, 1), 1 x 200000, dtype: object, indexer=memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999]), axis=1, verify=True, convert=True)\n   4006                 raise Exception('Indices must be nonzero and less than '\n   4007                                 'the axis length')\n   4008 \n   4009         new_labels = self.axes[axis].take(indexer)\n   4010         return self.reindex_indexer(new_axis=new_labels, indexer=indexer,\n-> 4011                                     axis=axis, allow_dups=True)\n        axis = 1\n   4012 \n   4013     def merge(self, other, lsuffix='', rsuffix=''):\n   4014         if not self._is_indexed_like(other):\n   4015             raise AssertionError('Must have same axes to merge managers')\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py in reindex_indexer(self=BlockManager\nItems: Index(['x1', 'x2', 'x3', 'x4...tBlock: slice(5, 6, 1), 1 x 200000, dtype: object, new_axis=Int64Index([ 39820,  39823,  39826,  39828,  398...199999],\n           dtype='int64', length=159999), indexer=memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999]), axis=1, fill_value=None, allow_dups=True, copy=True)\n   3892             new_blocks = self._slice_take_blocks_ax0(indexer,\n   3893                                                      fill_tuple=(fill_value,))\n   3894         else:\n   3895             new_blocks = [blk.take_nd(indexer, axis=axis, fill_tuple=(\n   3896                 fill_value if fill_value is not None else blk.fill_value,))\n-> 3897                 for blk in self.blocks]\n        self.blocks = (FloatBlock: slice(0, 5, 1), 5 x 200000, dtype: float64, ObjectBlock: slice(5, 6, 1), 1 x 200000, dtype: object)\n   3898 \n   3899         new_axes = list(self.axes)\n   3900         new_axes[axis] = new_axis\n   3901         return self.__class__(new_blocks, new_axes)\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py in <listcomp>(.0=<tuple_iterator object>)\n   3892             new_blocks = self._slice_take_blocks_ax0(indexer,\n   3893                                                      fill_tuple=(fill_value,))\n   3894         else:\n   3895             new_blocks = [blk.take_nd(indexer, axis=axis, fill_tuple=(\n   3896                 fill_value if fill_value is not None else blk.fill_value,))\n-> 3897                 for blk in self.blocks]\n        blk = FloatBlock: slice(0, 5, 1), 5 x 200000, dtype: float64\n   3898 \n   3899         new_axes = list(self.axes)\n   3900         new_axes[axis] = new_axis\n   3901         return self.__class__(new_blocks, new_axes)\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py in take_nd(self=FloatBlock: slice(0, 5, 1), 5 x 200000, dtype: float64, indexer=memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999]), axis=1, new_mgr_locs=None, fill_tuple=(nan,))\n   1041             new_values = algos.take_nd(values, indexer, axis=axis,\n   1042                                        allow_fill=False)\n   1043         else:\n   1044             fill_value = fill_tuple[0]\n   1045             new_values = algos.take_nd(values, indexer, axis=axis,\n-> 1046                                        allow_fill=True, fill_value=fill_value)\n        fill_value = nan\n   1047 \n   1048         if new_mgr_locs is None:\n   1049             if axis == 0:\n   1050                 slc = lib.indexer_as_slice(indexer)\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/algorithms.py in take_nd(arr=memmap([[-0.57082802, -1.01821463,  1.08032314, ... 1.87256242,\n         -0.38265788,  1.40318761]]), indexer=memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999]), axis=1, out=array([[ 0.45680369, -1.04423349,  0.77484853, .... -0.1491669 ,\n        -0.31025364,  1.40318761]]), fill_value=nan, mask_info=None, allow_fill=True)\n   1466         else:\n   1467             out = np.empty(out_shape, dtype=dtype)\n   1468 \n   1469     func = _get_take_nd_function(arr.ndim, arr.dtype, out.dtype, axis=axis,\n   1470                                  mask_info=mask_info)\n-> 1471     func(arr, indexer, out, fill_value)\n        func = <built-in function take_2d_axis1_float64_float64>\n        arr = memmap([[-0.57082802, -1.01821463,  1.08032314, ... 1.87256242,\n         -0.38265788,  1.40318761]])\n        indexer = memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999])\n        out = array([[ 0.45680369, -1.04423349,  0.77484853, .... -0.1491669 ,\n        -0.31025364,  1.40318761]])\n        fill_value = nan\n   1472 \n   1473     if flip_order:\n   1474         out = out.T\n   1475     return out\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/_libs/algos.cpython-36m-darwin.so in pandas._libs.algos.take_2d_axis1_float64_float64 (pandas/_libs/algos.c:111160)()\n   4629 \n   4630 \n   4631 \n   4632 \n   4633 \n-> 4634 \n   4635 \n   4636 \n   4637 \n   4638 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/_libs/algos.cpython-36m-darwin.so in View.MemoryView.memoryview_cwrapper (pandas/_libs/algos.c:124730)()\n    639 \n    640 \n    641 \n    642 \n    643 \n--> 644 \n    645 \n    646 \n    647 \n    648 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/_libs/algos.cpython-36m-darwin.so in View.MemoryView.memoryview.__cinit__ (pandas/_libs/algos.c:120965)()\n    340 \n    341 \n    342 \n    343 \n    344 \n--> 345 \n    346 \n    347 \n    348 \n    349 \n\nValueError: buffer source array is read-only\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/utils/__init__.py\", line 99, in safe_indexing\n    return X.iloc[indices]\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/indexing.py\", line 1328, in __getitem__\n    return self._getitem_axis(key, axis=0)\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/indexing.py\", line 1738, in _getitem_axis\n    return self._get_list_axis(key, axis=axis)\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/indexing.py\", line 1715, in _get_list_axis\n    return self.obj.take(key, axis=axis, convert=False)\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/generic.py\", line 1928, in take\n    convert=True, verify=True)\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py\", line 4011, in take\n    axis=axis, allow_dups=True)\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py\", line 3897, in reindex_indexer\n    for blk in self.blocks]\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py\", line 3897, in <listcomp>\n    for blk in self.blocks]\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py\", line 1046, in take_nd\n    allow_fill=True, fill_value=fill_value)\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/algorithms.py\", line 1471, in take_nd\n    func(arr, indexer, out, fill_value)\n  File \"pandas/_libs/algos_take_helper.pxi\", line 4809, in pandas._libs.algos.take_2d_axis0_object_object (pandas/_libs/algos.c:112602)\n  File \"stringsource\", line 644, in View.MemoryView.memoryview_cwrapper (pandas/_libs/algos.c:124730)\n  File \"stringsource\", line 345, in View.MemoryView.memoryview.__cinit__ (pandas/_libs/algos.c:120965)\nValueError: buffer source array is read-only\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 344, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 231, in _fit_and_score\n    X_train, y_train = _safe_split(estimator, X, y, train)\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/utils/metaestimators.py\", line 108, in _safe_split\n    X_subset = safe_indexing(X, indices)\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/utils/__init__.py\", line 105, in safe_indexing\n    return X.copy().iloc[indices]\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/indexing.py\", line 1328, in __getitem__\n    return self._getitem_axis(key, axis=0)\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/indexing.py\", line 1738, in _getitem_axis\n    return self._get_list_axis(key, axis=axis)\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/indexing.py\", line 1715, in _get_list_axis\n    return self.obj.take(key, axis=axis, convert=False)\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/generic.py\", line 1928, in take\n    convert=True, verify=True)\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py\", line 4011, in take\n    axis=axis, allow_dups=True)\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py\", line 3897, in reindex_indexer\n    for blk in self.blocks]\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py\", line 3897, in <listcomp>\n    for blk in self.blocks]\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py\", line 1046, in take_nd\n    allow_fill=True, fill_value=fill_value)\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/algorithms.py\", line 1471, in take_nd\n    func(arr, indexer, out, fill_value)\n  File \"pandas/_libs/algos_take_helper.pxi\", line 4634, in pandas._libs.algos.take_2d_axis1_float64_float64 (pandas/_libs/algos.c:111160)\n  File \"stringsource\", line 644, in View.MemoryView.memoryview_cwrapper (pandas/_libs/algos.c:124730)\n  File \"stringsource\", line 345, in View.MemoryView.memoryview.__cinit__ (pandas/_libs/algos.c:120965)\nValueError: buffer source array is read-only\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 353, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nValueError                                         Wed Aug  2 18:31:52 2017\nPID: 35368Python 3.6.1: /Users/gstoddard/anaconda/envs/standard_py3_env/bin/python\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('feature_encoder', DataFrame_En...None,\n            verbose=0, warm_start=False))]),               x1        x2        x3        x4  ...254  1.403188        a\n\n[200000 rows x 6 columns], memmap([0, 1, 0, ..., 1, 0, 1]), <function _passthrough_scorer>, memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999]), array([    0,     1,     2, ..., 40167, 40169, 40171]), 1, {'clf__n_estimators': 10}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('feature_encoder', DataFrame_En...None,\n            verbose=0, warm_start=False))]),               x1        x2        x3        x4  ...254  1.403188        a\n\n[200000 rows x 6 columns], memmap([0, 1, 0, ..., 1, 0, 1]), <function _passthrough_scorer>, memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999]), array([    0,     1,     2, ..., 40167, 40169, 40171]), 1, {'clf__n_estimators': 10})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('feature_encoder', DataFrame_En...None,\n            verbose=0, warm_start=False))]), X=              x1        x2        x3        x4  ...254  1.403188        a\n\n[200000 rows x 6 columns], y=memmap([0, 1, 0, ..., 1, 0, 1]), scorer=<function _passthrough_scorer>, train=memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999]), test=array([    0,     1,     2, ..., 40167, 40169, 40171]), verbose=1, parameters={'clf__n_estimators': 10}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    226     if parameters is not None:\n    227         estimator.set_params(**parameters)\n    228 \n    229     start_time = time.time()\n    230 \n--> 231     X_train, y_train = _safe_split(estimator, X, y, train)\n        X_train = undefined\n        y_train = undefined\n        estimator = Pipeline(steps=[('feature_encoder', DataFrame_En...None,\n            verbose=0, warm_start=False))])\n        X =               x1        x2        x3        x4  ...254  1.403188        a\n\n[200000 rows x 6 columns]\n        y = memmap([0, 1, 0, ..., 1, 0, 1])\n        train = memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999])\n    232     X_test, y_test = _safe_split(estimator, X, y, test, train)\n    233 \n    234     try:\n    235         if y_train is None:\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/utils/metaestimators.py in _safe_split(estimator=Pipeline(steps=[('feature_encoder', DataFrame_En...None,\n            verbose=0, warm_start=False))]), X=              x1        x2        x3        x4  ...254  1.403188        a\n\n[200000 rows x 6 columns], y=memmap([0, 1, 0, ..., 1, 0, 1]), indices=memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999]), train_indices=None)\n    103             if train_indices is None:\n    104                 X_subset = X[np.ix_(indices, indices)]\n    105             else:\n    106                 X_subset = X[np.ix_(indices, train_indices)]\n    107         else:\n--> 108             X_subset = safe_indexing(X, indices)\n        X_subset = undefined\n        X =               x1        x2        x3        x4  ...254  1.403188        a\n\n[200000 rows x 6 columns]\n        indices = memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999])\n    109 \n    110     if y is not None:\n    111         y_subset = safe_indexing(y, indices)\n    112     else:\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/utils/__init__.py in safe_indexing(X=              x1        x2        x3        x4  ...254  1.403188        a\n\n[200000 rows x 6 columns], indices=memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999]))\n    100         except ValueError:\n    101             # Cython typed memoryviews internally used in pandas do not support\n    102             # readonly buffers.\n    103             warnings.warn(\"Copying input dataframe for slicing.\",\n    104                           DataConversionWarning)\n--> 105             return X.copy().iloc[indices]\n        X.copy.iloc = undefined\n        indices = memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999])\n    106     elif hasattr(X, \"shape\"):\n    107         if hasattr(X, 'take') and (hasattr(indices, 'dtype') and\n    108                                    indices.dtype.kind == 'i'):\n    109             # This is often substantially faster than X[indices]\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self=<pandas.core.indexing._iLocIndexer object>, key=memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999]))\n   1323             except (KeyError, IndexError):\n   1324                 pass\n   1325             return self._getitem_tuple(key)\n   1326         else:\n   1327             key = com._apply_if_callable(key, self.obj)\n-> 1328             return self._getitem_axis(key, axis=0)\n        self._getitem_axis = <bound method _iLocIndexer._getitem_axis of <pandas.core.indexing._iLocIndexer object>>\n        key = memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999])\n   1329 \n   1330     def _is_scalar_access(self, key):\n   1331         raise NotImplementedError()\n   1332 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self=<pandas.core.indexing._iLocIndexer object>, key=memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999]), axis=0)\n   1733             self._has_valid_type(key, axis)\n   1734             return self._getbool_axis(key, axis=axis)\n   1735 \n   1736         # a list of integers\n   1737         elif is_list_like_indexer(key):\n-> 1738             return self._get_list_axis(key, axis=axis)\n        self._get_list_axis = <bound method _iLocIndexer._get_list_axis of <pandas.core.indexing._iLocIndexer object>>\n        key = memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999])\n        axis = 0\n   1739 \n   1740         # a single integer\n   1741         else:\n   1742             key = self._convert_scalar_indexer(key, axis)\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/indexing.py in _get_list_axis(self=<pandas.core.indexing._iLocIndexer object>, key=memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999]), axis=0)\n   1710         Returns\n   1711         -------\n   1712         Series object\n   1713         \"\"\"\n   1714         try:\n-> 1715             return self.obj.take(key, axis=axis, convert=False)\n        self.obj.take = <bound method NDFrame.take of               x1  ...54  1.403188        a\n\n[200000 rows x 6 columns]>\n        key = memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999])\n        axis = 0\n   1716         except IndexError:\n   1717             # re-raise with different error message\n   1718             raise IndexError(\"positional indexers are out-of-bounds\")\n   1719 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/generic.py in take(self=              x1        x2        x3        x4  ...254  1.403188        a\n\n[200000 rows x 6 columns], indices=memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999]), axis=0, convert=False, is_copy=True, **kwargs={})\n   1923         \"\"\"\n   1924         nv.validate_take(tuple(), kwargs)\n   1925         self._consolidate_inplace()\n   1926         new_data = self._data.take(indices,\n   1927                                    axis=self._get_block_manager_axis(axis),\n-> 1928                                    convert=True, verify=True)\n        convert = False\n   1929         result = self._constructor(new_data).__finalize__(self)\n   1930 \n   1931         # maybe set copy if we didn't actually change the index\n   1932         if is_copy:\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py in take(self=BlockManager\nItems: Index(['x1', 'x2', 'x3', 'x4...tBlock: slice(5, 6, 1), 1 x 200000, dtype: object, indexer=memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999]), axis=1, verify=True, convert=True)\n   4006                 raise Exception('Indices must be nonzero and less than '\n   4007                                 'the axis length')\n   4008 \n   4009         new_labels = self.axes[axis].take(indexer)\n   4010         return self.reindex_indexer(new_axis=new_labels, indexer=indexer,\n-> 4011                                     axis=axis, allow_dups=True)\n        axis = 1\n   4012 \n   4013     def merge(self, other, lsuffix='', rsuffix=''):\n   4014         if not self._is_indexed_like(other):\n   4015             raise AssertionError('Must have same axes to merge managers')\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py in reindex_indexer(self=BlockManager\nItems: Index(['x1', 'x2', 'x3', 'x4...tBlock: slice(5, 6, 1), 1 x 200000, dtype: object, new_axis=Int64Index([ 39820,  39823,  39826,  39828,  398...199999],\n           dtype='int64', length=159999), indexer=memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999]), axis=1, fill_value=None, allow_dups=True, copy=True)\n   3892             new_blocks = self._slice_take_blocks_ax0(indexer,\n   3893                                                      fill_tuple=(fill_value,))\n   3894         else:\n   3895             new_blocks = [blk.take_nd(indexer, axis=axis, fill_tuple=(\n   3896                 fill_value if fill_value is not None else blk.fill_value,))\n-> 3897                 for blk in self.blocks]\n        self.blocks = (FloatBlock: slice(0, 5, 1), 5 x 200000, dtype: float64, ObjectBlock: slice(5, 6, 1), 1 x 200000, dtype: object)\n   3898 \n   3899         new_axes = list(self.axes)\n   3900         new_axes[axis] = new_axis\n   3901         return self.__class__(new_blocks, new_axes)\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py in <listcomp>(.0=<tuple_iterator object>)\n   3892             new_blocks = self._slice_take_blocks_ax0(indexer,\n   3893                                                      fill_tuple=(fill_value,))\n   3894         else:\n   3895             new_blocks = [blk.take_nd(indexer, axis=axis, fill_tuple=(\n   3896                 fill_value if fill_value is not None else blk.fill_value,))\n-> 3897                 for blk in self.blocks]\n        blk = FloatBlock: slice(0, 5, 1), 5 x 200000, dtype: float64\n   3898 \n   3899         new_axes = list(self.axes)\n   3900         new_axes[axis] = new_axis\n   3901         return self.__class__(new_blocks, new_axes)\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py in take_nd(self=FloatBlock: slice(0, 5, 1), 5 x 200000, dtype: float64, indexer=memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999]), axis=1, new_mgr_locs=None, fill_tuple=(nan,))\n   1041             new_values = algos.take_nd(values, indexer, axis=axis,\n   1042                                        allow_fill=False)\n   1043         else:\n   1044             fill_value = fill_tuple[0]\n   1045             new_values = algos.take_nd(values, indexer, axis=axis,\n-> 1046                                        allow_fill=True, fill_value=fill_value)\n        fill_value = nan\n   1047 \n   1048         if new_mgr_locs is None:\n   1049             if axis == 0:\n   1050                 slc = lib.indexer_as_slice(indexer)\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/algorithms.py in take_nd(arr=memmap([[-0.57082802, -1.01821463,  1.08032314, ... 1.87256242,\n         -0.38265788,  1.40318761]]), indexer=memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999]), axis=1, out=array([[ 0.45680369, -1.04423349,  0.77484853, .... -0.1491669 ,\n        -0.31025364,  1.40318761]]), fill_value=nan, mask_info=None, allow_fill=True)\n   1466         else:\n   1467             out = np.empty(out_shape, dtype=dtype)\n   1468 \n   1469     func = _get_take_nd_function(arr.ndim, arr.dtype, out.dtype, axis=axis,\n   1470                                  mask_info=mask_info)\n-> 1471     func(arr, indexer, out, fill_value)\n        func = <built-in function take_2d_axis1_float64_float64>\n        arr = memmap([[-0.57082802, -1.01821463,  1.08032314, ... 1.87256242,\n         -0.38265788,  1.40318761]])\n        indexer = memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999])\n        out = array([[ 0.45680369, -1.04423349,  0.77484853, .... -0.1491669 ,\n        -0.31025364,  1.40318761]])\n        fill_value = nan\n   1472 \n   1473     if flip_order:\n   1474         out = out.T\n   1475     return out\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/_libs/algos.cpython-36m-darwin.so in pandas._libs.algos.take_2d_axis1_float64_float64 (pandas/_libs/algos.c:111160)()\n   4629 \n   4630 \n   4631 \n   4632 \n   4633 \n-> 4634 \n   4635 \n   4636 \n   4637 \n   4638 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/_libs/algos.cpython-36m-darwin.so in View.MemoryView.memoryview_cwrapper (pandas/_libs/algos.c:124730)()\n    639 \n    640 \n    641 \n    642 \n    643 \n--> 644 \n    645 \n    646 \n    647 \n    648 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/_libs/algos.cpython-36m-darwin.so in View.MemoryView.memoryview.__cinit__ (pandas/_libs/algos.c:120965)()\n    340 \n    341 \n    342 \n    343 \n    344 \n--> 345 \n    346 \n    347 \n    348 \n    349 \n\nValueError: buffer source array is read-only\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    681\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m'timeout'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetfullargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Wed Aug  2 18:31:52 2017\nPID: 35368Python 3.6.1: /Users/gstoddard/anaconda/envs/standard_py3_env/bin/python\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('feature_encoder', DataFrame_En...None,\n            verbose=0, warm_start=False))]),               x1        x2        x3        x4  ...254  1.403188        a\n\n[200000 rows x 6 columns], memmap([0, 1, 0, ..., 1, 0, 1]), <function _passthrough_scorer>, memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999]), array([    0,     1,     2, ..., 40167, 40169, 40171]), 1, {'clf__n_estimators': 10}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('feature_encoder', DataFrame_En...None,\n            verbose=0, warm_start=False))]),               x1        x2        x3        x4  ...254  1.403188        a\n\n[200000 rows x 6 columns], memmap([0, 1, 0, ..., 1, 0, 1]), <function _passthrough_scorer>, memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999]), array([    0,     1,     2, ..., 40167, 40169, 40171]), 1, {'clf__n_estimators': 10})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('feature_encoder', DataFrame_En...None,\n            verbose=0, warm_start=False))]), X=              x1        x2        x3        x4  ...254  1.403188        a\n\n[200000 rows x 6 columns], y=memmap([0, 1, 0, ..., 1, 0, 1]), scorer=<function _passthrough_scorer>, train=memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999]), test=array([    0,     1,     2, ..., 40167, 40169, 40171]), verbose=1, parameters={'clf__n_estimators': 10}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    226     if parameters is not None:\n    227         estimator.set_params(**parameters)\n    228 \n    229     start_time = time.time()\n    230 \n--> 231     X_train, y_train = _safe_split(estimator, X, y, train)\n        X_train = undefined\n        y_train = undefined\n        estimator = Pipeline(steps=[('feature_encoder', DataFrame_En...None,\n            verbose=0, warm_start=False))])\n        X =               x1        x2        x3        x4  ...254  1.403188        a\n\n[200000 rows x 6 columns]\n        y = memmap([0, 1, 0, ..., 1, 0, 1])\n        train = memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999])\n    232     X_test, y_test = _safe_split(estimator, X, y, test, train)\n    233 \n    234     try:\n    235         if y_train is None:\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/utils/metaestimators.py in _safe_split(estimator=Pipeline(steps=[('feature_encoder', DataFrame_En...None,\n            verbose=0, warm_start=False))]), X=              x1        x2        x3        x4  ...254  1.403188        a\n\n[200000 rows x 6 columns], y=memmap([0, 1, 0, ..., 1, 0, 1]), indices=memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999]), train_indices=None)\n    103             if train_indices is None:\n    104                 X_subset = X[np.ix_(indices, indices)]\n    105             else:\n    106                 X_subset = X[np.ix_(indices, train_indices)]\n    107         else:\n--> 108             X_subset = safe_indexing(X, indices)\n        X_subset = undefined\n        X =               x1        x2        x3        x4  ...254  1.403188        a\n\n[200000 rows x 6 columns]\n        indices = memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999])\n    109 \n    110     if y is not None:\n    111         y_subset = safe_indexing(y, indices)\n    112     else:\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/utils/__init__.py in safe_indexing(X=              x1        x2        x3        x4  ...254  1.403188        a\n\n[200000 rows x 6 columns], indices=memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999]))\n    100         except ValueError:\n    101             # Cython typed memoryviews internally used in pandas do not support\n    102             # readonly buffers.\n    103             warnings.warn(\"Copying input dataframe for slicing.\",\n    104                           DataConversionWarning)\n--> 105             return X.copy().iloc[indices]\n        X.copy.iloc = undefined\n        indices = memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999])\n    106     elif hasattr(X, \"shape\"):\n    107         if hasattr(X, 'take') and (hasattr(indices, 'dtype') and\n    108                                    indices.dtype.kind == 'i'):\n    109             # This is often substantially faster than X[indices]\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self=<pandas.core.indexing._iLocIndexer object>, key=memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999]))\n   1323             except (KeyError, IndexError):\n   1324                 pass\n   1325             return self._getitem_tuple(key)\n   1326         else:\n   1327             key = com._apply_if_callable(key, self.obj)\n-> 1328             return self._getitem_axis(key, axis=0)\n        self._getitem_axis = <bound method _iLocIndexer._getitem_axis of <pandas.core.indexing._iLocIndexer object>>\n        key = memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999])\n   1329 \n   1330     def _is_scalar_access(self, key):\n   1331         raise NotImplementedError()\n   1332 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self=<pandas.core.indexing._iLocIndexer object>, key=memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999]), axis=0)\n   1733             self._has_valid_type(key, axis)\n   1734             return self._getbool_axis(key, axis=axis)\n   1735 \n   1736         # a list of integers\n   1737         elif is_list_like_indexer(key):\n-> 1738             return self._get_list_axis(key, axis=axis)\n        self._get_list_axis = <bound method _iLocIndexer._get_list_axis of <pandas.core.indexing._iLocIndexer object>>\n        key = memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999])\n        axis = 0\n   1739 \n   1740         # a single integer\n   1741         else:\n   1742             key = self._convert_scalar_indexer(key, axis)\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/indexing.py in _get_list_axis(self=<pandas.core.indexing._iLocIndexer object>, key=memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999]), axis=0)\n   1710         Returns\n   1711         -------\n   1712         Series object\n   1713         \"\"\"\n   1714         try:\n-> 1715             return self.obj.take(key, axis=axis, convert=False)\n        self.obj.take = <bound method NDFrame.take of               x1  ...54  1.403188        a\n\n[200000 rows x 6 columns]>\n        key = memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999])\n        axis = 0\n   1716         except IndexError:\n   1717             # re-raise with different error message\n   1718             raise IndexError(\"positional indexers are out-of-bounds\")\n   1719 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/generic.py in take(self=              x1        x2        x3        x4  ...254  1.403188        a\n\n[200000 rows x 6 columns], indices=memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999]), axis=0, convert=False, is_copy=True, **kwargs={})\n   1923         \"\"\"\n   1924         nv.validate_take(tuple(), kwargs)\n   1925         self._consolidate_inplace()\n   1926         new_data = self._data.take(indices,\n   1927                                    axis=self._get_block_manager_axis(axis),\n-> 1928                                    convert=True, verify=True)\n        convert = False\n   1929         result = self._constructor(new_data).__finalize__(self)\n   1930 \n   1931         # maybe set copy if we didn't actually change the index\n   1932         if is_copy:\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py in take(self=BlockManager\nItems: Index(['x1', 'x2', 'x3', 'x4...tBlock: slice(5, 6, 1), 1 x 200000, dtype: object, indexer=memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999]), axis=1, verify=True, convert=True)\n   4006                 raise Exception('Indices must be nonzero and less than '\n   4007                                 'the axis length')\n   4008 \n   4009         new_labels = self.axes[axis].take(indexer)\n   4010         return self.reindex_indexer(new_axis=new_labels, indexer=indexer,\n-> 4011                                     axis=axis, allow_dups=True)\n        axis = 1\n   4012 \n   4013     def merge(self, other, lsuffix='', rsuffix=''):\n   4014         if not self._is_indexed_like(other):\n   4015             raise AssertionError('Must have same axes to merge managers')\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py in reindex_indexer(self=BlockManager\nItems: Index(['x1', 'x2', 'x3', 'x4...tBlock: slice(5, 6, 1), 1 x 200000, dtype: object, new_axis=Int64Index([ 39820,  39823,  39826,  39828,  398...199999],\n           dtype='int64', length=159999), indexer=memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999]), axis=1, fill_value=None, allow_dups=True, copy=True)\n   3892             new_blocks = self._slice_take_blocks_ax0(indexer,\n   3893                                                      fill_tuple=(fill_value,))\n   3894         else:\n   3895             new_blocks = [blk.take_nd(indexer, axis=axis, fill_tuple=(\n   3896                 fill_value if fill_value is not None else blk.fill_value,))\n-> 3897                 for blk in self.blocks]\n        self.blocks = (FloatBlock: slice(0, 5, 1), 5 x 200000, dtype: float64, ObjectBlock: slice(5, 6, 1), 1 x 200000, dtype: object)\n   3898 \n   3899         new_axes = list(self.axes)\n   3900         new_axes[axis] = new_axis\n   3901         return self.__class__(new_blocks, new_axes)\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py in <listcomp>(.0=<tuple_iterator object>)\n   3892             new_blocks = self._slice_take_blocks_ax0(indexer,\n   3893                                                      fill_tuple=(fill_value,))\n   3894         else:\n   3895             new_blocks = [blk.take_nd(indexer, axis=axis, fill_tuple=(\n   3896                 fill_value if fill_value is not None else blk.fill_value,))\n-> 3897                 for blk in self.blocks]\n        blk = FloatBlock: slice(0, 5, 1), 5 x 200000, dtype: float64\n   3898 \n   3899         new_axes = list(self.axes)\n   3900         new_axes[axis] = new_axis\n   3901         return self.__class__(new_blocks, new_axes)\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py in take_nd(self=FloatBlock: slice(0, 5, 1), 5 x 200000, dtype: float64, indexer=memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999]), axis=1, new_mgr_locs=None, fill_tuple=(nan,))\n   1041             new_values = algos.take_nd(values, indexer, axis=axis,\n   1042                                        allow_fill=False)\n   1043         else:\n   1044             fill_value = fill_tuple[0]\n   1045             new_values = algos.take_nd(values, indexer, axis=axis,\n-> 1046                                        allow_fill=True, fill_value=fill_value)\n        fill_value = nan\n   1047 \n   1048         if new_mgr_locs is None:\n   1049             if axis == 0:\n   1050                 slc = lib.indexer_as_slice(indexer)\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/algorithms.py in take_nd(arr=memmap([[-0.57082802, -1.01821463,  1.08032314, ... 1.87256242,\n         -0.38265788,  1.40318761]]), indexer=memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999]), axis=1, out=array([[ 0.45680369, -1.04423349,  0.77484853, .... -0.1491669 ,\n        -0.31025364,  1.40318761]]), fill_value=nan, mask_info=None, allow_fill=True)\n   1466         else:\n   1467             out = np.empty(out_shape, dtype=dtype)\n   1468 \n   1469     func = _get_take_nd_function(arr.ndim, arr.dtype, out.dtype, axis=axis,\n   1470                                  mask_info=mask_info)\n-> 1471     func(arr, indexer, out, fill_value)\n        func = <built-in function take_2d_axis1_float64_float64>\n        arr = memmap([[-0.57082802, -1.01821463,  1.08032314, ... 1.87256242,\n         -0.38265788,  1.40318761]])\n        indexer = memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999])\n        out = array([[ 0.45680369, -1.04423349,  0.77484853, .... -0.1491669 ,\n        -0.31025364,  1.40318761]])\n        fill_value = nan\n   1472 \n   1473     if flip_order:\n   1474         out = out.T\n   1475     return out\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/_libs/algos.cpython-36m-darwin.so in pandas._libs.algos.take_2d_axis1_float64_float64 (pandas/_libs/algos.c:111160)()\n   4629 \n   4630 \n   4631 \n   4632 \n   4633 \n-> 4634 \n   4635 \n   4636 \n   4637 \n   4638 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/_libs/algos.cpython-36m-darwin.so in View.MemoryView.memoryview_cwrapper (pandas/_libs/algos.c:124730)()\n    639 \n    640 \n    641 \n    642 \n    643 \n--> 644 \n    645 \n    646 \n    647 \n    648 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/_libs/algos.cpython-36m-darwin.so in View.MemoryView.memoryview.__cinit__ (pandas/_libs/algos.c:120965)()\n    340 \n    341 \n    342 \n    343 \n    344 \n--> 345 \n    346 \n    347 \n    348 \n    349 \n\nValueError: buffer source array is read-only\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-a373d1acd0e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtest\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \"\"\"\n\u001b[0;32m--> 945\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                   \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m--> 564\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m           for train, test in cv_iter)\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x10e8bd030, file \"/Use...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/Users/gstoddard/anaconda/envs/standard_py3_env/...ges/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/Users/gstod.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x10e8bd030, file \"/Use...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/Users/gstoddard/anaconda/envs/standard_py3_env/...ges/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/Users/gstod.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n     17 \n     18 \n     19 \n     20 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'x,y = make_classification(n_samples=200000,n_fea...ram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 8, 2, 22, 31, 52, 510190, tzinfo=tzutc()), 'msg_id': 'D98F82F152284DFFA8552ADFF17725A4', 'msg_type': 'execute_request', 'session': 'A09FD675E3EA46CB837CBE1D3E75F32E', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'D98F82F152284DFFA8552ADFF17725A4', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'A09FD675E3EA46CB837CBE1D3E75F32E']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'x,y = make_classification(n_samples=200000,n_fea...ram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 8, 2, 22, 31, 52, 510190, tzinfo=tzutc()), 'msg_id': 'D98F82F152284DFFA8552ADFF17725A4', 'msg_type': 'execute_request', 'session': 'A09FD675E3EA46CB837CBE1D3E75F32E', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'D98F82F152284DFFA8552ADFF17725A4', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'A09FD675E3EA46CB837CBE1D3E75F32E'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'x,y = make_classification(n_samples=200000,n_fea...ram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 8, 2, 22, 31, 52, 510190, tzinfo=tzutc()), 'msg_id': 'D98F82F152284DFFA8552ADFF17725A4', 'msg_type': 'execute_request', 'session': 'A09FD675E3EA46CB837CBE1D3E75F32E', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'D98F82F152284DFFA8552ADFF17725A4', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='x,y = make_classification(n_samples=200000,n_fea...ram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)\\n', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'x,y = make_classification(n_samples=200000,n_fea...ram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)\\n'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('x,y = make_classification(n_samples=200000,n_fea...ram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)\\n',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('x,y = make_classification(n_samples=200000,n_fea...ram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)\\n',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='x,y = make_classification(n_samples=200000,n_fea...ram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)\\n', store_history=True, silent=False, shell_futures=True)\n   2678                 self.displayhook.exec_result = result\n   2679 \n   2680                 # Execute the user code\n   2681                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2682                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2683                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2684                 \n   2685                 self.last_execution_succeeded = not has_raised\n   2686 \n   2687                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-4-a373d1acd0e6>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 1196c4390, execution_..._before_exec=None error_in_exec=None result=None>)\n   2788                     return True\n   2789 \n   2790             for i, node in enumerate(to_run_interactive):\n   2791                 mod = ast.Interactive([node])\n   2792                 code = compiler(mod, cell_name, \"single\")\n-> 2793                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x1195a45d0, file \"<ipython-input-4-a373d1acd0e6>\", line 21>\n        result = <ExecutionResult object at 1196c4390, execution_..._before_exec=None error_in_exec=None result=None>\n   2794                     return True\n   2795 \n   2796             # Flush softspace\n   2797             if softspace(sys.stdout, 0):\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x1195a45d0, file \"<ipython-input-4-a373d1acd0e6>\", line 21>, result=<ExecutionResult object at 1196c4390, execution_..._before_exec=None error_in_exec=None result=None>)\n   2842         outflag = True  # happens in more places, so it's easier as default\n   2843         try:\n   2844             try:\n   2845                 self.hooks.pre_run_code_hook()\n   2846                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2847                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x1195a45d0, file \"<ipython-input-4-a373d1acd0e6>\", line 21>\n        self.user_global_ns = {'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'DataFrame_Encoder': <class '__main__.DataFrame_Encoder'>, 'DictVectorizer': <class 'sklearn.feature_extraction.dict_vectorizer.DictVectorizer'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import pandas as pd\\n\\nfrom sklearn.model_selectio...raction import DictVectorizer\\n\\nimport numpy as np', 'class DataFrame_Encoder(BaseEstimator, Transform..., categorical_df],axis=1)\\n        return new_data', 'x,y = make_classification(n_samples=200000,n_fea...aram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)', 'x,y = make_classification(n_samples=200000,n_fea...aram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)'], 'Out': {}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'TransformerMixin': <class 'sklearn.base.TransformerMixin'>, '_': '', ...}\n        self.user_ns = {'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'DataFrame_Encoder': <class '__main__.DataFrame_Encoder'>, 'DictVectorizer': <class 'sklearn.feature_extraction.dict_vectorizer.DictVectorizer'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import pandas as pd\\n\\nfrom sklearn.model_selectio...raction import DictVectorizer\\n\\nimport numpy as np', 'class DataFrame_Encoder(BaseEstimator, Transform..., categorical_df],axis=1)\\n        return new_data', 'x,y = make_classification(n_samples=200000,n_fea...aram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)', 'x,y = make_classification(n_samples=200000,n_fea...aram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)'], 'Out': {}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'TransformerMixin': <class 'sklearn.base.TransformerMixin'>, '_': '', ...}\n   2848             finally:\n   2849                 # Reset our crash handler in place\n   2850                 sys.excepthook = old_excepthook\n   2851         except SystemExit as e:\n\n...........................................................................\n/Users/gstoddard/sklearn_bug/<ipython-input-4-a373d1acd0e6> in <module>()\n     16 ])\n     17 pipeline.set_params(feature_encoder__categorical_cols_=string_features, feature_encoder__numeric_cols_=numeric_features)\n     18 \n     19 clf = GridSearchCV(pipeline, param_grid,cv=5,n_jobs=2,verbose=1)\n     20 \n---> 21 clf.fit(df,y)\n     22 \n     23 \n     24 \n     25 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...train_score=True,\n       scoring=None, verbose=1), X=              x1        x2        x3        x4  ...254  1.403188        a\n\n[200000 rows x 6 columns], y=array([0, 1, 0, ..., 1, 0, 1]), groups=None)\n    940 \n    941         groups : array-like, with shape (n_samples,), optional\n    942             Group labels for the samples used while splitting the dataset into\n    943             train/test set.\n    944         \"\"\"\n--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))\n        self._fit = <bound method BaseSearchCV._fit of GridSearchCV(...rain_score=True,\n       scoring=None, verbose=1)>\n        X =               x1        x2        x3        x4  ...254  1.403188        a\n\n[200000 rows x 6 columns]\n        y = array([0, 1, 0, ..., 1, 0, 1])\n        groups = None\n        self.param_grid = {'clf__n_estimators': [10, 100]}\n    946 \n    947 \n    948 class RandomizedSearchCV(BaseSearchCV):\n    949     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...train_score=True,\n       scoring=None, verbose=1), X=              x1        x2        x3        x4  ...254  1.403188        a\n\n[200000 rows x 6 columns], y=array([0, 1, 0, ..., 1, 0, 1]), groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)\n    559                                   fit_params=self.fit_params,\n    560                                   return_train_score=self.return_train_score,\n    561                                   return_n_test_samples=True,\n    562                                   return_times=True, return_parameters=True,\n    563                                   error_score=self.error_score)\n--> 564           for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>\n    565           for train, test in cv_iter)\n    566 \n    567         # if one choose to see train score, \"out\" will contain train score info\n    568         if self.return_train_score:\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=2), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=2)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Wed Aug  2 18:31:52 2017\nPID: 35368Python 3.6.1: /Users/gstoddard/anaconda/envs/standard_py3_env/bin/python\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('feature_encoder', DataFrame_En...None,\n            verbose=0, warm_start=False))]),               x1        x2        x3        x4  ...254  1.403188        a\n\n[200000 rows x 6 columns], memmap([0, 1, 0, ..., 1, 0, 1]), <function _passthrough_scorer>, memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999]), array([    0,     1,     2, ..., 40167, 40169, 40171]), 1, {'clf__n_estimators': 10}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('feature_encoder', DataFrame_En...None,\n            verbose=0, warm_start=False))]),               x1        x2        x3        x4  ...254  1.403188        a\n\n[200000 rows x 6 columns], memmap([0, 1, 0, ..., 1, 0, 1]), <function _passthrough_scorer>, memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999]), array([    0,     1,     2, ..., 40167, 40169, 40171]), 1, {'clf__n_estimators': 10})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('feature_encoder', DataFrame_En...None,\n            verbose=0, warm_start=False))]), X=              x1        x2        x3        x4  ...254  1.403188        a\n\n[200000 rows x 6 columns], y=memmap([0, 1, 0, ..., 1, 0, 1]), scorer=<function _passthrough_scorer>, train=memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999]), test=array([    0,     1,     2, ..., 40167, 40169, 40171]), verbose=1, parameters={'clf__n_estimators': 10}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    226     if parameters is not None:\n    227         estimator.set_params(**parameters)\n    228 \n    229     start_time = time.time()\n    230 \n--> 231     X_train, y_train = _safe_split(estimator, X, y, train)\n        X_train = undefined\n        y_train = undefined\n        estimator = Pipeline(steps=[('feature_encoder', DataFrame_En...None,\n            verbose=0, warm_start=False))])\n        X =               x1        x2        x3        x4  ...254  1.403188        a\n\n[200000 rows x 6 columns]\n        y = memmap([0, 1, 0, ..., 1, 0, 1])\n        train = memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999])\n    232     X_test, y_test = _safe_split(estimator, X, y, test, train)\n    233 \n    234     try:\n    235         if y_train is None:\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/utils/metaestimators.py in _safe_split(estimator=Pipeline(steps=[('feature_encoder', DataFrame_En...None,\n            verbose=0, warm_start=False))]), X=              x1        x2        x3        x4  ...254  1.403188        a\n\n[200000 rows x 6 columns], y=memmap([0, 1, 0, ..., 1, 0, 1]), indices=memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999]), train_indices=None)\n    103             if train_indices is None:\n    104                 X_subset = X[np.ix_(indices, indices)]\n    105             else:\n    106                 X_subset = X[np.ix_(indices, train_indices)]\n    107         else:\n--> 108             X_subset = safe_indexing(X, indices)\n        X_subset = undefined\n        X =               x1        x2        x3        x4  ...254  1.403188        a\n\n[200000 rows x 6 columns]\n        indices = memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999])\n    109 \n    110     if y is not None:\n    111         y_subset = safe_indexing(y, indices)\n    112     else:\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/utils/__init__.py in safe_indexing(X=              x1        x2        x3        x4  ...254  1.403188        a\n\n[200000 rows x 6 columns], indices=memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999]))\n    100         except ValueError:\n    101             # Cython typed memoryviews internally used in pandas do not support\n    102             # readonly buffers.\n    103             warnings.warn(\"Copying input dataframe for slicing.\",\n    104                           DataConversionWarning)\n--> 105             return X.copy().iloc[indices]\n        X.copy.iloc = undefined\n        indices = memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999])\n    106     elif hasattr(X, \"shape\"):\n    107         if hasattr(X, 'take') and (hasattr(indices, 'dtype') and\n    108                                    indices.dtype.kind == 'i'):\n    109             # This is often substantially faster than X[indices]\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self=<pandas.core.indexing._iLocIndexer object>, key=memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999]))\n   1323             except (KeyError, IndexError):\n   1324                 pass\n   1325             return self._getitem_tuple(key)\n   1326         else:\n   1327             key = com._apply_if_callable(key, self.obj)\n-> 1328             return self._getitem_axis(key, axis=0)\n        self._getitem_axis = <bound method _iLocIndexer._getitem_axis of <pandas.core.indexing._iLocIndexer object>>\n        key = memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999])\n   1329 \n   1330     def _is_scalar_access(self, key):\n   1331         raise NotImplementedError()\n   1332 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self=<pandas.core.indexing._iLocIndexer object>, key=memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999]), axis=0)\n   1733             self._has_valid_type(key, axis)\n   1734             return self._getbool_axis(key, axis=axis)\n   1735 \n   1736         # a list of integers\n   1737         elif is_list_like_indexer(key):\n-> 1738             return self._get_list_axis(key, axis=axis)\n        self._get_list_axis = <bound method _iLocIndexer._get_list_axis of <pandas.core.indexing._iLocIndexer object>>\n        key = memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999])\n        axis = 0\n   1739 \n   1740         # a single integer\n   1741         else:\n   1742             key = self._convert_scalar_indexer(key, axis)\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/indexing.py in _get_list_axis(self=<pandas.core.indexing._iLocIndexer object>, key=memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999]), axis=0)\n   1710         Returns\n   1711         -------\n   1712         Series object\n   1713         \"\"\"\n   1714         try:\n-> 1715             return self.obj.take(key, axis=axis, convert=False)\n        self.obj.take = <bound method NDFrame.take of               x1  ...54  1.403188        a\n\n[200000 rows x 6 columns]>\n        key = memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999])\n        axis = 0\n   1716         except IndexError:\n   1717             # re-raise with different error message\n   1718             raise IndexError(\"positional indexers are out-of-bounds\")\n   1719 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/generic.py in take(self=              x1        x2        x3        x4  ...254  1.403188        a\n\n[200000 rows x 6 columns], indices=memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999]), axis=0, convert=False, is_copy=True, **kwargs={})\n   1923         \"\"\"\n   1924         nv.validate_take(tuple(), kwargs)\n   1925         self._consolidate_inplace()\n   1926         new_data = self._data.take(indices,\n   1927                                    axis=self._get_block_manager_axis(axis),\n-> 1928                                    convert=True, verify=True)\n        convert = False\n   1929         result = self._constructor(new_data).__finalize__(self)\n   1930 \n   1931         # maybe set copy if we didn't actually change the index\n   1932         if is_copy:\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py in take(self=BlockManager\nItems: Index(['x1', 'x2', 'x3', 'x4...tBlock: slice(5, 6, 1), 1 x 200000, dtype: object, indexer=memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999]), axis=1, verify=True, convert=True)\n   4006                 raise Exception('Indices must be nonzero and less than '\n   4007                                 'the axis length')\n   4008 \n   4009         new_labels = self.axes[axis].take(indexer)\n   4010         return self.reindex_indexer(new_axis=new_labels, indexer=indexer,\n-> 4011                                     axis=axis, allow_dups=True)\n        axis = 1\n   4012 \n   4013     def merge(self, other, lsuffix='', rsuffix=''):\n   4014         if not self._is_indexed_like(other):\n   4015             raise AssertionError('Must have same axes to merge managers')\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py in reindex_indexer(self=BlockManager\nItems: Index(['x1', 'x2', 'x3', 'x4...tBlock: slice(5, 6, 1), 1 x 200000, dtype: object, new_axis=Int64Index([ 39820,  39823,  39826,  39828,  398...199999],\n           dtype='int64', length=159999), indexer=memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999]), axis=1, fill_value=None, allow_dups=True, copy=True)\n   3892             new_blocks = self._slice_take_blocks_ax0(indexer,\n   3893                                                      fill_tuple=(fill_value,))\n   3894         else:\n   3895             new_blocks = [blk.take_nd(indexer, axis=axis, fill_tuple=(\n   3896                 fill_value if fill_value is not None else blk.fill_value,))\n-> 3897                 for blk in self.blocks]\n        self.blocks = (FloatBlock: slice(0, 5, 1), 5 x 200000, dtype: float64, ObjectBlock: slice(5, 6, 1), 1 x 200000, dtype: object)\n   3898 \n   3899         new_axes = list(self.axes)\n   3900         new_axes[axis] = new_axis\n   3901         return self.__class__(new_blocks, new_axes)\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py in <listcomp>(.0=<tuple_iterator object>)\n   3892             new_blocks = self._slice_take_blocks_ax0(indexer,\n   3893                                                      fill_tuple=(fill_value,))\n   3894         else:\n   3895             new_blocks = [blk.take_nd(indexer, axis=axis, fill_tuple=(\n   3896                 fill_value if fill_value is not None else blk.fill_value,))\n-> 3897                 for blk in self.blocks]\n        blk = FloatBlock: slice(0, 5, 1), 5 x 200000, dtype: float64\n   3898 \n   3899         new_axes = list(self.axes)\n   3900         new_axes[axis] = new_axis\n   3901         return self.__class__(new_blocks, new_axes)\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py in take_nd(self=FloatBlock: slice(0, 5, 1), 5 x 200000, dtype: float64, indexer=memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999]), axis=1, new_mgr_locs=None, fill_tuple=(nan,))\n   1041             new_values = algos.take_nd(values, indexer, axis=axis,\n   1042                                        allow_fill=False)\n   1043         else:\n   1044             fill_value = fill_tuple[0]\n   1045             new_values = algos.take_nd(values, indexer, axis=axis,\n-> 1046                                        allow_fill=True, fill_value=fill_value)\n        fill_value = nan\n   1047 \n   1048         if new_mgr_locs is None:\n   1049             if axis == 0:\n   1050                 slc = lib.indexer_as_slice(indexer)\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/algorithms.py in take_nd(arr=memmap([[-0.57082802, -1.01821463,  1.08032314, ... 1.87256242,\n         -0.38265788,  1.40318761]]), indexer=memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999]), axis=1, out=array([[ 0.45680369, -1.04423349,  0.77484853, .... -0.1491669 ,\n        -0.31025364,  1.40318761]]), fill_value=nan, mask_info=None, allow_fill=True)\n   1466         else:\n   1467             out = np.empty(out_shape, dtype=dtype)\n   1468 \n   1469     func = _get_take_nd_function(arr.ndim, arr.dtype, out.dtype, axis=axis,\n   1470                                  mask_info=mask_info)\n-> 1471     func(arr, indexer, out, fill_value)\n        func = <built-in function take_2d_axis1_float64_float64>\n        arr = memmap([[-0.57082802, -1.01821463,  1.08032314, ... 1.87256242,\n         -0.38265788,  1.40318761]])\n        indexer = memmap([ 39820,  39823,  39826, ..., 199997, 199998, 199999])\n        out = array([[ 0.45680369, -1.04423349,  0.77484853, .... -0.1491669 ,\n        -0.31025364,  1.40318761]])\n        fill_value = nan\n   1472 \n   1473     if flip_order:\n   1474         out = out.T\n   1475     return out\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/_libs/algos.cpython-36m-darwin.so in pandas._libs.algos.take_2d_axis1_float64_float64 (pandas/_libs/algos.c:111160)()\n   4629 \n   4630 \n   4631 \n   4632 \n   4633 \n-> 4634 \n   4635 \n   4636 \n   4637 \n   4638 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/_libs/algos.cpython-36m-darwin.so in View.MemoryView.memoryview_cwrapper (pandas/_libs/algos.c:124730)()\n    639 \n    640 \n    641 \n    642 \n    643 \n--> 644 \n    645 \n    646 \n    647 \n    648 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/_libs/algos.cpython-36m-darwin.so in View.MemoryView.memoryview.__cinit__ (pandas/_libs/algos.c:120965)()\n    340 \n    341 \n    342 \n    343 \n    344 \n--> 345 \n    346 \n    347 \n    348 \n    349 \n\nValueError: buffer source array is read-only\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "x,y = make_classification(n_samples=200000,n_features=5)\n",
    "\n",
    "numeric_features = ['x1','x2','x3','x4','x5']\n",
    "string_features = []\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data=x,columns=numeric_features)\n",
    "df['category'] = 'a'\n",
    "\n",
    "base_clf = RandomForestClassifier(n_jobs=4)\n",
    "param_grid = {'clf__n_estimators':[10,100]}\n",
    "\n",
    "pipeline = Pipeline([\n",
    "        ('feature_encoder',DataFrame_Encoder()),\n",
    "        ('clf',base_clf)\n",
    "])\n",
    "pipeline.set_params(feature_encoder__categorical_cols_=string_features, feature_encoder__numeric_cols_=numeric_features)\n",
    "\n",
    "clf = GridSearchCV(pipeline, param_grid,cv=5,n_jobs=2,verbose=1)\n",
    "\n",
    "clf.fit(df,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3: Fails\n",
    "\n",
    "We now use a different encoder that simply drops any Object columns from a Dataframe. Even with this encoder, it fails. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/utils/__init__.py:104: DataConversionWarning: Copying input dataframe for slicing.\n",
      "  DataConversionWarning)\n",
      "/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/utils/__init__.py:104: DataConversionWarning: Copying input dataframe for slicing.\n",
      "  DataConversionWarning)\n",
      "/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/utils/__init__.py:104: DataConversionWarning: Copying input dataframe for slicing.\n",
      "  DataConversionWarning)\n"
     ]
    },
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x10e8bd030, file \"/Use...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/Users/gstoddard/anaconda/envs/standard_py3_env/...ges/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/Users/gstod.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x10e8bd030, file \"/Use...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/Users/gstoddard/anaconda/envs/standard_py3_env/...ges/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/Users/gstod.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n     17 \n     18 \n     19 \n     20 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'class DropString_Encoder(BaseEstimator, Transfor...ram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 8, 2, 22, 31, 58, 246994, tzinfo=tzutc()), 'msg_id': '43497E3ACF714AAB98CB24992E51E772', 'msg_type': 'execute_request', 'session': 'A09FD675E3EA46CB837CBE1D3E75F32E', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '43497E3ACF714AAB98CB24992E51E772', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'A09FD675E3EA46CB837CBE1D3E75F32E']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'class DropString_Encoder(BaseEstimator, Transfor...ram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 8, 2, 22, 31, 58, 246994, tzinfo=tzutc()), 'msg_id': '43497E3ACF714AAB98CB24992E51E772', 'msg_type': 'execute_request', 'session': 'A09FD675E3EA46CB837CBE1D3E75F32E', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '43497E3ACF714AAB98CB24992E51E772', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'A09FD675E3EA46CB837CBE1D3E75F32E'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'class DropString_Encoder(BaseEstimator, Transfor...ram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 8, 2, 22, 31, 58, 246994, tzinfo=tzutc()), 'msg_id': '43497E3ACF714AAB98CB24992E51E772', 'msg_type': 'execute_request', 'session': 'A09FD675E3EA46CB837CBE1D3E75F32E', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '43497E3ACF714AAB98CB24992E51E772', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='class DropString_Encoder(BaseEstimator, Transfor...ram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)\\n', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'class DropString_Encoder(BaseEstimator, Transfor...ram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)\\n'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('class DropString_Encoder(BaseEstimator, Transfor...ram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)\\n',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('class DropString_Encoder(BaseEstimator, Transfor...ram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)\\n',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='class DropString_Encoder(BaseEstimator, Transfor...ram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)\\n', store_history=True, silent=False, shell_futures=True)\n   2678                 self.displayhook.exec_result = result\n   2679 \n   2680                 # Execute the user code\n   2681                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2682                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2683                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2684                 \n   2685                 self.last_execution_succeeded = not has_raised\n   2686 \n   2687                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.ClassDef object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-5-d5101a6a0bf9>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 119632668, execution_..._before_exec=None error_in_exec=None result=None>)\n   2788                     return True\n   2789 \n   2790             for i, node in enumerate(to_run_interactive):\n   2791                 mod = ast.Interactive([node])\n   2792                 code = compiler(mod, cell_name, \"single\")\n-> 2793                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x1196b6540, file \"<ipython-input-5-d5101a6a0bf9>\", line 30>\n        result = <ExecutionResult object at 119632668, execution_..._before_exec=None error_in_exec=None result=None>\n   2794                     return True\n   2795 \n   2796             # Flush softspace\n   2797             if softspace(sys.stdout, 0):\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x1196b6540, file \"<ipython-input-5-d5101a6a0bf9>\", line 30>, result=<ExecutionResult object at 119632668, execution_..._before_exec=None error_in_exec=None result=None>)\n   2842         outflag = True  # happens in more places, so it's easier as default\n   2843         try:\n   2844             try:\n   2845                 self.hooks.pre_run_code_hook()\n   2846                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2847                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x1196b6540, file \"<ipython-input-5-d5101a6a0bf9>\", line 30>\n        self.user_global_ns = {'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'DataFrame_Encoder': <class '__main__.DataFrame_Encoder'>, 'DictVectorizer': <class 'sklearn.feature_extraction.dict_vectorizer.DictVectorizer'>, 'DropString_Encoder': <class '__main__.DropString_Encoder'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import pandas as pd\\n\\nfrom sklearn.model_selectio...raction import DictVectorizer\\n\\nimport numpy as np', 'class DataFrame_Encoder(BaseEstimator, Transform..., categorical_df],axis=1)\\n        return new_data', 'x,y = make_classification(n_samples=200000,n_fea...aram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)', 'x,y = make_classification(n_samples=200000,n_fea...aram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)', 'class DropString_Encoder(BaseEstimator, Transfor...aram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)'], 'Out': {}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'TransformerMixin': <class 'sklearn.base.TransformerMixin'>, ...}\n        self.user_ns = {'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'DataFrame_Encoder': <class '__main__.DataFrame_Encoder'>, 'DictVectorizer': <class 'sklearn.feature_extraction.dict_vectorizer.DictVectorizer'>, 'DropString_Encoder': <class '__main__.DropString_Encoder'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import pandas as pd\\n\\nfrom sklearn.model_selectio...raction import DictVectorizer\\n\\nimport numpy as np', 'class DataFrame_Encoder(BaseEstimator, Transform..., categorical_df],axis=1)\\n        return new_data', 'x,y = make_classification(n_samples=200000,n_fea...aram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)', 'x,y = make_classification(n_samples=200000,n_fea...aram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)', 'class DropString_Encoder(BaseEstimator, Transfor...aram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)'], 'Out': {}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'TransformerMixin': <class 'sklearn.base.TransformerMixin'>, ...}\n   2848             finally:\n   2849                 # Reset our crash handler in place\n   2850                 sys.excepthook = old_excepthook\n   2851         except SystemExit as e:\n\n...........................................................................\n/Users/gstoddard/sklearn_bug/<ipython-input-5-d5101a6a0bf9> in <module>()\n     25         ('clf',base_clf)\n     26 ])\n     27 \n     28 clf = GridSearchCV(pipeline, param_grid,cv=5,n_jobs=2,verbose=1)\n     29 \n---> 30 clf.fit(df,y)\n     31 \n     32 \n     33 \n     34 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...train_score=True,\n       scoring=None, verbose=1), X=              x1        x2        x3        x4  ...160 -2.339500        a\n\n[200000 rows x 6 columns], y=array([0, 1, 0, ..., 0, 1, 1]), groups=None)\n    940 \n    941         groups : array-like, with shape (n_samples,), optional\n    942             Group labels for the samples used while splitting the dataset into\n    943             train/test set.\n    944         \"\"\"\n--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))\n        self._fit = <bound method BaseSearchCV._fit of GridSearchCV(...rain_score=True,\n       scoring=None, verbose=1)>\n        X =               x1        x2        x3        x4  ...160 -2.339500        a\n\n[200000 rows x 6 columns]\n        y = array([0, 1, 0, ..., 0, 1, 1])\n        groups = None\n        self.param_grid = {'clf__n_estimators': [10, 100]}\n    946 \n    947 \n    948 class RandomizedSearchCV(BaseSearchCV):\n    949     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...train_score=True,\n       scoring=None, verbose=1), X=              x1        x2        x3        x4  ...160 -2.339500        a\n\n[200000 rows x 6 columns], y=array([0, 1, 0, ..., 0, 1, 1]), groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)\n    559                                   fit_params=self.fit_params,\n    560                                   return_train_score=self.return_train_score,\n    561                                   return_n_test_samples=True,\n    562                                   return_times=True, return_parameters=True,\n    563                                   error_score=self.error_score)\n--> 564           for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>\n    565           for train, test in cv_iter)\n    566 \n    567         # if one choose to see train score, \"out\" will contain train score info\n    568         if self.return_train_score:\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=2), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=2)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Wed Aug  2 18:31:58 2017\nPID: 35370Python 3.6.1: /Users/gstoddard/anaconda/envs/standard_py3_env/bin/python\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('feature_encoder', DropString_E...None,\n            verbose=0, warm_start=False))]),               x1        x2        x3        x4  ...160 -2.339500        a\n\n[200000 rows x 6 columns], memmap([0, 1, 0, ..., 0, 1, 1]), <function _passthrough_scorer>, memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999]), array([    0,     1,     2, ..., 40168, 40171, 40174]), 1, {'clf__n_estimators': 10}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('feature_encoder', DropString_E...None,\n            verbose=0, warm_start=False))]),               x1        x2        x3        x4  ...160 -2.339500        a\n\n[200000 rows x 6 columns], memmap([0, 1, 0, ..., 0, 1, 1]), <function _passthrough_scorer>, memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999]), array([    0,     1,     2, ..., 40168, 40171, 40174]), 1, {'clf__n_estimators': 10})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('feature_encoder', DropString_E...None,\n            verbose=0, warm_start=False))]), X=              x1        x2        x3        x4  ...160 -2.339500        a\n\n[200000 rows x 6 columns], y=memmap([0, 1, 0, ..., 0, 1, 1]), scorer=<function _passthrough_scorer>, train=memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999]), test=array([    0,     1,     2, ..., 40168, 40171, 40174]), verbose=1, parameters={'clf__n_estimators': 10}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    226     if parameters is not None:\n    227         estimator.set_params(**parameters)\n    228 \n    229     start_time = time.time()\n    230 \n--> 231     X_train, y_train = _safe_split(estimator, X, y, train)\n        X_train = undefined\n        y_train = undefined\n        estimator = Pipeline(steps=[('feature_encoder', DropString_E...None,\n            verbose=0, warm_start=False))])\n        X =               x1        x2        x3        x4  ...160 -2.339500        a\n\n[200000 rows x 6 columns]\n        y = memmap([0, 1, 0, ..., 0, 1, 1])\n        train = memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999])\n    232     X_test, y_test = _safe_split(estimator, X, y, test, train)\n    233 \n    234     try:\n    235         if y_train is None:\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/utils/metaestimators.py in _safe_split(estimator=Pipeline(steps=[('feature_encoder', DropString_E...None,\n            verbose=0, warm_start=False))]), X=              x1        x2        x3        x4  ...160 -2.339500        a\n\n[200000 rows x 6 columns], y=memmap([0, 1, 0, ..., 0, 1, 1]), indices=memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999]), train_indices=None)\n    103             if train_indices is None:\n    104                 X_subset = X[np.ix_(indices, indices)]\n    105             else:\n    106                 X_subset = X[np.ix_(indices, train_indices)]\n    107         else:\n--> 108             X_subset = safe_indexing(X, indices)\n        X_subset = undefined\n        X =               x1        x2        x3        x4  ...160 -2.339500        a\n\n[200000 rows x 6 columns]\n        indices = memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999])\n    109 \n    110     if y is not None:\n    111         y_subset = safe_indexing(y, indices)\n    112     else:\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/utils/__init__.py in safe_indexing(X=              x1        x2        x3        x4  ...160 -2.339500        a\n\n[200000 rows x 6 columns], indices=memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999]))\n    100         except ValueError:\n    101             # Cython typed memoryviews internally used in pandas do not support\n    102             # readonly buffers.\n    103             warnings.warn(\"Copying input dataframe for slicing.\",\n    104                           DataConversionWarning)\n--> 105             return X.copy().iloc[indices]\n        X.copy.iloc = undefined\n        indices = memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999])\n    106     elif hasattr(X, \"shape\"):\n    107         if hasattr(X, 'take') and (hasattr(indices, 'dtype') and\n    108                                    indices.dtype.kind == 'i'):\n    109             # This is often substantially faster than X[indices]\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self=<pandas.core.indexing._iLocIndexer object>, key=memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999]))\n   1323             except (KeyError, IndexError):\n   1324                 pass\n   1325             return self._getitem_tuple(key)\n   1326         else:\n   1327             key = com._apply_if_callable(key, self.obj)\n-> 1328             return self._getitem_axis(key, axis=0)\n        self._getitem_axis = <bound method _iLocIndexer._getitem_axis of <pandas.core.indexing._iLocIndexer object>>\n        key = memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999])\n   1329 \n   1330     def _is_scalar_access(self, key):\n   1331         raise NotImplementedError()\n   1332 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self=<pandas.core.indexing._iLocIndexer object>, key=memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999]), axis=0)\n   1733             self._has_valid_type(key, axis)\n   1734             return self._getbool_axis(key, axis=axis)\n   1735 \n   1736         # a list of integers\n   1737         elif is_list_like_indexer(key):\n-> 1738             return self._get_list_axis(key, axis=axis)\n        self._get_list_axis = <bound method _iLocIndexer._get_list_axis of <pandas.core.indexing._iLocIndexer object>>\n        key = memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999])\n        axis = 0\n   1739 \n   1740         # a single integer\n   1741         else:\n   1742             key = self._convert_scalar_indexer(key, axis)\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/indexing.py in _get_list_axis(self=<pandas.core.indexing._iLocIndexer object>, key=memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999]), axis=0)\n   1710         Returns\n   1711         -------\n   1712         Series object\n   1713         \"\"\"\n   1714         try:\n-> 1715             return self.obj.take(key, axis=axis, convert=False)\n        self.obj.take = <bound method NDFrame.take of               x1  ...60 -2.339500        a\n\n[200000 rows x 6 columns]>\n        key = memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999])\n        axis = 0\n   1716         except IndexError:\n   1717             # re-raise with different error message\n   1718             raise IndexError(\"positional indexers are out-of-bounds\")\n   1719 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/generic.py in take(self=              x1        x2        x3        x4  ...160 -2.339500        a\n\n[200000 rows x 6 columns], indices=memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999]), axis=0, convert=False, is_copy=True, **kwargs={})\n   1923         \"\"\"\n   1924         nv.validate_take(tuple(), kwargs)\n   1925         self._consolidate_inplace()\n   1926         new_data = self._data.take(indices,\n   1927                                    axis=self._get_block_manager_axis(axis),\n-> 1928                                    convert=True, verify=True)\n        convert = False\n   1929         result = self._constructor(new_data).__finalize__(self)\n   1930 \n   1931         # maybe set copy if we didn't actually change the index\n   1932         if is_copy:\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py in take(self=BlockManager\nItems: Index(['x1', 'x2', 'x3', 'x4...tBlock: slice(5, 6, 1), 1 x 200000, dtype: object, indexer=memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999]), axis=1, verify=True, convert=True)\n   4006                 raise Exception('Indices must be nonzero and less than '\n   4007                                 'the axis length')\n   4008 \n   4009         new_labels = self.axes[axis].take(indexer)\n   4010         return self.reindex_indexer(new_axis=new_labels, indexer=indexer,\n-> 4011                                     axis=axis, allow_dups=True)\n        axis = 1\n   4012 \n   4013     def merge(self, other, lsuffix='', rsuffix=''):\n   4014         if not self._is_indexed_like(other):\n   4015             raise AssertionError('Must have same axes to merge managers')\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py in reindex_indexer(self=BlockManager\nItems: Index(['x1', 'x2', 'x3', 'x4...tBlock: slice(5, 6, 1), 1 x 200000, dtype: object, new_axis=Int64Index([ 39804,  39805,  39808,  39816,  398...199999],\n           dtype='int64', length=159999), indexer=memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999]), axis=1, fill_value=None, allow_dups=True, copy=True)\n   3892             new_blocks = self._slice_take_blocks_ax0(indexer,\n   3893                                                      fill_tuple=(fill_value,))\n   3894         else:\n   3895             new_blocks = [blk.take_nd(indexer, axis=axis, fill_tuple=(\n   3896                 fill_value if fill_value is not None else blk.fill_value,))\n-> 3897                 for blk in self.blocks]\n        self.blocks = (FloatBlock: slice(0, 5, 1), 5 x 200000, dtype: float64, ObjectBlock: slice(5, 6, 1), 1 x 200000, dtype: object)\n   3898 \n   3899         new_axes = list(self.axes)\n   3900         new_axes[axis] = new_axis\n   3901         return self.__class__(new_blocks, new_axes)\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py in <listcomp>(.0=<tuple_iterator object>)\n   3892             new_blocks = self._slice_take_blocks_ax0(indexer,\n   3893                                                      fill_tuple=(fill_value,))\n   3894         else:\n   3895             new_blocks = [blk.take_nd(indexer, axis=axis, fill_tuple=(\n   3896                 fill_value if fill_value is not None else blk.fill_value,))\n-> 3897                 for blk in self.blocks]\n        blk = FloatBlock: slice(0, 5, 1), 5 x 200000, dtype: float64\n   3898 \n   3899         new_axes = list(self.axes)\n   3900         new_axes[axis] = new_axis\n   3901         return self.__class__(new_blocks, new_axes)\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py in take_nd(self=FloatBlock: slice(0, 5, 1), 5 x 200000, dtype: float64, indexer=memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999]), axis=1, new_mgr_locs=None, fill_tuple=(nan,))\n   1041             new_values = algos.take_nd(values, indexer, axis=axis,\n   1042                                        allow_fill=False)\n   1043         else:\n   1044             fill_value = fill_tuple[0]\n   1045             new_values = algos.take_nd(values, indexer, axis=axis,\n-> 1046                                        allow_fill=True, fill_value=fill_value)\n        fill_value = nan\n   1047 \n   1048         if new_mgr_locs is None:\n   1049             if axis == 0:\n   1050                 slc = lib.indexer_as_slice(indexer)\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/algorithms.py in take_nd(arr=memmap([[ 0.23953029, -0.50635937,  1.40387008, ... 1.38955039,\n         -0.74704499, -2.33949991]]), indexer=memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999]), axis=1, out=array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n    ...0.],\n       [ 0.,  0.,  0., ...,  0.,  0.,  0.]]), fill_value=nan, mask_info=None, allow_fill=True)\n   1466         else:\n   1467             out = np.empty(out_shape, dtype=dtype)\n   1468 \n   1469     func = _get_take_nd_function(arr.ndim, arr.dtype, out.dtype, axis=axis,\n   1470                                  mask_info=mask_info)\n-> 1471     func(arr, indexer, out, fill_value)\n        func = <built-in function take_2d_axis1_float64_float64>\n        arr = memmap([[ 0.23953029, -0.50635937,  1.40387008, ... 1.38955039,\n         -0.74704499, -2.33949991]])\n        indexer = memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999])\n        out = array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n    ...0.],\n       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])\n        fill_value = nan\n   1472 \n   1473     if flip_order:\n   1474         out = out.T\n   1475     return out\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/_libs/algos.cpython-36m-darwin.so in pandas._libs.algos.take_2d_axis1_float64_float64 (pandas/_libs/algos.c:111160)()\n   4629 \n   4630 \n   4631 \n   4632 \n   4633 \n-> 4634 \n   4635 \n   4636 \n   4637 \n   4638 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/_libs/algos.cpython-36m-darwin.so in View.MemoryView.memoryview_cwrapper (pandas/_libs/algos.c:124730)()\n    639 \n    640 \n    641 \n    642 \n    643 \n--> 644 \n    645 \n    646 \n    647 \n    648 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/_libs/algos.cpython-36m-darwin.so in View.MemoryView.memoryview.__cinit__ (pandas/_libs/algos.c:120965)()\n    340 \n    341 \n    342 \n    343 \n    344 \n--> 345 \n    346 \n    347 \n    348 \n    349 \n\nValueError: buffer source array is read-only\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/utils/__init__.py\", line 99, in safe_indexing\n    return X.iloc[indices]\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/indexing.py\", line 1328, in __getitem__\n    return self._getitem_axis(key, axis=0)\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/indexing.py\", line 1738, in _getitem_axis\n    return self._get_list_axis(key, axis=axis)\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/indexing.py\", line 1715, in _get_list_axis\n    return self.obj.take(key, axis=axis, convert=False)\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/generic.py\", line 1928, in take\n    convert=True, verify=True)\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py\", line 4011, in take\n    axis=axis, allow_dups=True)\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py\", line 3897, in reindex_indexer\n    for blk in self.blocks]\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py\", line 3897, in <listcomp>\n    for blk in self.blocks]\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py\", line 1046, in take_nd\n    allow_fill=True, fill_value=fill_value)\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/algorithms.py\", line 1471, in take_nd\n    func(arr, indexer, out, fill_value)\n  File \"pandas/_libs/algos_take_helper.pxi\", line 4809, in pandas._libs.algos.take_2d_axis0_object_object (pandas/_libs/algos.c:112602)\n  File \"stringsource\", line 644, in View.MemoryView.memoryview_cwrapper (pandas/_libs/algos.c:124730)\n  File \"stringsource\", line 345, in View.MemoryView.memoryview.__cinit__ (pandas/_libs/algos.c:120965)\nValueError: buffer source array is read-only\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 344, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 231, in _fit_and_score\n    X_train, y_train = _safe_split(estimator, X, y, train)\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/utils/metaestimators.py\", line 108, in _safe_split\n    X_subset = safe_indexing(X, indices)\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/utils/__init__.py\", line 105, in safe_indexing\n    return X.copy().iloc[indices]\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/indexing.py\", line 1328, in __getitem__\n    return self._getitem_axis(key, axis=0)\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/indexing.py\", line 1738, in _getitem_axis\n    return self._get_list_axis(key, axis=axis)\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/indexing.py\", line 1715, in _get_list_axis\n    return self.obj.take(key, axis=axis, convert=False)\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/generic.py\", line 1928, in take\n    convert=True, verify=True)\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py\", line 4011, in take\n    axis=axis, allow_dups=True)\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py\", line 3897, in reindex_indexer\n    for blk in self.blocks]\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py\", line 3897, in <listcomp>\n    for blk in self.blocks]\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py\", line 1046, in take_nd\n    allow_fill=True, fill_value=fill_value)\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/algorithms.py\", line 1471, in take_nd\n    func(arr, indexer, out, fill_value)\n  File \"pandas/_libs/algos_take_helper.pxi\", line 4634, in pandas._libs.algos.take_2d_axis1_float64_float64 (pandas/_libs/algos.c:111160)\n  File \"stringsource\", line 644, in View.MemoryView.memoryview_cwrapper (pandas/_libs/algos.c:124730)\n  File \"stringsource\", line 345, in View.MemoryView.memoryview.__cinit__ (pandas/_libs/algos.c:120965)\nValueError: buffer source array is read-only\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 353, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nValueError                                         Wed Aug  2 18:31:58 2017\nPID: 35370Python 3.6.1: /Users/gstoddard/anaconda/envs/standard_py3_env/bin/python\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('feature_encoder', DropString_E...None,\n            verbose=0, warm_start=False))]),               x1        x2        x3        x4  ...160 -2.339500        a\n\n[200000 rows x 6 columns], memmap([0, 1, 0, ..., 0, 1, 1]), <function _passthrough_scorer>, memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999]), array([    0,     1,     2, ..., 40168, 40171, 40174]), 1, {'clf__n_estimators': 10}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('feature_encoder', DropString_E...None,\n            verbose=0, warm_start=False))]),               x1        x2        x3        x4  ...160 -2.339500        a\n\n[200000 rows x 6 columns], memmap([0, 1, 0, ..., 0, 1, 1]), <function _passthrough_scorer>, memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999]), array([    0,     1,     2, ..., 40168, 40171, 40174]), 1, {'clf__n_estimators': 10})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('feature_encoder', DropString_E...None,\n            verbose=0, warm_start=False))]), X=              x1        x2        x3        x4  ...160 -2.339500        a\n\n[200000 rows x 6 columns], y=memmap([0, 1, 0, ..., 0, 1, 1]), scorer=<function _passthrough_scorer>, train=memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999]), test=array([    0,     1,     2, ..., 40168, 40171, 40174]), verbose=1, parameters={'clf__n_estimators': 10}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    226     if parameters is not None:\n    227         estimator.set_params(**parameters)\n    228 \n    229     start_time = time.time()\n    230 \n--> 231     X_train, y_train = _safe_split(estimator, X, y, train)\n        X_train = undefined\n        y_train = undefined\n        estimator = Pipeline(steps=[('feature_encoder', DropString_E...None,\n            verbose=0, warm_start=False))])\n        X =               x1        x2        x3        x4  ...160 -2.339500        a\n\n[200000 rows x 6 columns]\n        y = memmap([0, 1, 0, ..., 0, 1, 1])\n        train = memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999])\n    232     X_test, y_test = _safe_split(estimator, X, y, test, train)\n    233 \n    234     try:\n    235         if y_train is None:\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/utils/metaestimators.py in _safe_split(estimator=Pipeline(steps=[('feature_encoder', DropString_E...None,\n            verbose=0, warm_start=False))]), X=              x1        x2        x3        x4  ...160 -2.339500        a\n\n[200000 rows x 6 columns], y=memmap([0, 1, 0, ..., 0, 1, 1]), indices=memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999]), train_indices=None)\n    103             if train_indices is None:\n    104                 X_subset = X[np.ix_(indices, indices)]\n    105             else:\n    106                 X_subset = X[np.ix_(indices, train_indices)]\n    107         else:\n--> 108             X_subset = safe_indexing(X, indices)\n        X_subset = undefined\n        X =               x1        x2        x3        x4  ...160 -2.339500        a\n\n[200000 rows x 6 columns]\n        indices = memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999])\n    109 \n    110     if y is not None:\n    111         y_subset = safe_indexing(y, indices)\n    112     else:\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/utils/__init__.py in safe_indexing(X=              x1        x2        x3        x4  ...160 -2.339500        a\n\n[200000 rows x 6 columns], indices=memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999]))\n    100         except ValueError:\n    101             # Cython typed memoryviews internally used in pandas do not support\n    102             # readonly buffers.\n    103             warnings.warn(\"Copying input dataframe for slicing.\",\n    104                           DataConversionWarning)\n--> 105             return X.copy().iloc[indices]\n        X.copy.iloc = undefined\n        indices = memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999])\n    106     elif hasattr(X, \"shape\"):\n    107         if hasattr(X, 'take') and (hasattr(indices, 'dtype') and\n    108                                    indices.dtype.kind == 'i'):\n    109             # This is often substantially faster than X[indices]\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self=<pandas.core.indexing._iLocIndexer object>, key=memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999]))\n   1323             except (KeyError, IndexError):\n   1324                 pass\n   1325             return self._getitem_tuple(key)\n   1326         else:\n   1327             key = com._apply_if_callable(key, self.obj)\n-> 1328             return self._getitem_axis(key, axis=0)\n        self._getitem_axis = <bound method _iLocIndexer._getitem_axis of <pandas.core.indexing._iLocIndexer object>>\n        key = memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999])\n   1329 \n   1330     def _is_scalar_access(self, key):\n   1331         raise NotImplementedError()\n   1332 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self=<pandas.core.indexing._iLocIndexer object>, key=memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999]), axis=0)\n   1733             self._has_valid_type(key, axis)\n   1734             return self._getbool_axis(key, axis=axis)\n   1735 \n   1736         # a list of integers\n   1737         elif is_list_like_indexer(key):\n-> 1738             return self._get_list_axis(key, axis=axis)\n        self._get_list_axis = <bound method _iLocIndexer._get_list_axis of <pandas.core.indexing._iLocIndexer object>>\n        key = memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999])\n        axis = 0\n   1739 \n   1740         # a single integer\n   1741         else:\n   1742             key = self._convert_scalar_indexer(key, axis)\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/indexing.py in _get_list_axis(self=<pandas.core.indexing._iLocIndexer object>, key=memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999]), axis=0)\n   1710         Returns\n   1711         -------\n   1712         Series object\n   1713         \"\"\"\n   1714         try:\n-> 1715             return self.obj.take(key, axis=axis, convert=False)\n        self.obj.take = <bound method NDFrame.take of               x1  ...60 -2.339500        a\n\n[200000 rows x 6 columns]>\n        key = memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999])\n        axis = 0\n   1716         except IndexError:\n   1717             # re-raise with different error message\n   1718             raise IndexError(\"positional indexers are out-of-bounds\")\n   1719 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/generic.py in take(self=              x1        x2        x3        x4  ...160 -2.339500        a\n\n[200000 rows x 6 columns], indices=memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999]), axis=0, convert=False, is_copy=True, **kwargs={})\n   1923         \"\"\"\n   1924         nv.validate_take(tuple(), kwargs)\n   1925         self._consolidate_inplace()\n   1926         new_data = self._data.take(indices,\n   1927                                    axis=self._get_block_manager_axis(axis),\n-> 1928                                    convert=True, verify=True)\n        convert = False\n   1929         result = self._constructor(new_data).__finalize__(self)\n   1930 \n   1931         # maybe set copy if we didn't actually change the index\n   1932         if is_copy:\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py in take(self=BlockManager\nItems: Index(['x1', 'x2', 'x3', 'x4...tBlock: slice(5, 6, 1), 1 x 200000, dtype: object, indexer=memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999]), axis=1, verify=True, convert=True)\n   4006                 raise Exception('Indices must be nonzero and less than '\n   4007                                 'the axis length')\n   4008 \n   4009         new_labels = self.axes[axis].take(indexer)\n   4010         return self.reindex_indexer(new_axis=new_labels, indexer=indexer,\n-> 4011                                     axis=axis, allow_dups=True)\n        axis = 1\n   4012 \n   4013     def merge(self, other, lsuffix='', rsuffix=''):\n   4014         if not self._is_indexed_like(other):\n   4015             raise AssertionError('Must have same axes to merge managers')\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py in reindex_indexer(self=BlockManager\nItems: Index(['x1', 'x2', 'x3', 'x4...tBlock: slice(5, 6, 1), 1 x 200000, dtype: object, new_axis=Int64Index([ 39804,  39805,  39808,  39816,  398...199999],\n           dtype='int64', length=159999), indexer=memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999]), axis=1, fill_value=None, allow_dups=True, copy=True)\n   3892             new_blocks = self._slice_take_blocks_ax0(indexer,\n   3893                                                      fill_tuple=(fill_value,))\n   3894         else:\n   3895             new_blocks = [blk.take_nd(indexer, axis=axis, fill_tuple=(\n   3896                 fill_value if fill_value is not None else blk.fill_value,))\n-> 3897                 for blk in self.blocks]\n        self.blocks = (FloatBlock: slice(0, 5, 1), 5 x 200000, dtype: float64, ObjectBlock: slice(5, 6, 1), 1 x 200000, dtype: object)\n   3898 \n   3899         new_axes = list(self.axes)\n   3900         new_axes[axis] = new_axis\n   3901         return self.__class__(new_blocks, new_axes)\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py in <listcomp>(.0=<tuple_iterator object>)\n   3892             new_blocks = self._slice_take_blocks_ax0(indexer,\n   3893                                                      fill_tuple=(fill_value,))\n   3894         else:\n   3895             new_blocks = [blk.take_nd(indexer, axis=axis, fill_tuple=(\n   3896                 fill_value if fill_value is not None else blk.fill_value,))\n-> 3897                 for blk in self.blocks]\n        blk = FloatBlock: slice(0, 5, 1), 5 x 200000, dtype: float64\n   3898 \n   3899         new_axes = list(self.axes)\n   3900         new_axes[axis] = new_axis\n   3901         return self.__class__(new_blocks, new_axes)\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py in take_nd(self=FloatBlock: slice(0, 5, 1), 5 x 200000, dtype: float64, indexer=memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999]), axis=1, new_mgr_locs=None, fill_tuple=(nan,))\n   1041             new_values = algos.take_nd(values, indexer, axis=axis,\n   1042                                        allow_fill=False)\n   1043         else:\n   1044             fill_value = fill_tuple[0]\n   1045             new_values = algos.take_nd(values, indexer, axis=axis,\n-> 1046                                        allow_fill=True, fill_value=fill_value)\n        fill_value = nan\n   1047 \n   1048         if new_mgr_locs is None:\n   1049             if axis == 0:\n   1050                 slc = lib.indexer_as_slice(indexer)\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/algorithms.py in take_nd(arr=memmap([[ 0.23953029, -0.50635937,  1.40387008, ... 1.38955039,\n         -0.74704499, -2.33949991]]), indexer=memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999]), axis=1, out=array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n    ...0.],\n       [ 0.,  0.,  0., ...,  0.,  0.,  0.]]), fill_value=nan, mask_info=None, allow_fill=True)\n   1466         else:\n   1467             out = np.empty(out_shape, dtype=dtype)\n   1468 \n   1469     func = _get_take_nd_function(arr.ndim, arr.dtype, out.dtype, axis=axis,\n   1470                                  mask_info=mask_info)\n-> 1471     func(arr, indexer, out, fill_value)\n        func = <built-in function take_2d_axis1_float64_float64>\n        arr = memmap([[ 0.23953029, -0.50635937,  1.40387008, ... 1.38955039,\n         -0.74704499, -2.33949991]])\n        indexer = memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999])\n        out = array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n    ...0.],\n       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])\n        fill_value = nan\n   1472 \n   1473     if flip_order:\n   1474         out = out.T\n   1475     return out\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/_libs/algos.cpython-36m-darwin.so in pandas._libs.algos.take_2d_axis1_float64_float64 (pandas/_libs/algos.c:111160)()\n   4629 \n   4630 \n   4631 \n   4632 \n   4633 \n-> 4634 \n   4635 \n   4636 \n   4637 \n   4638 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/_libs/algos.cpython-36m-darwin.so in View.MemoryView.memoryview_cwrapper (pandas/_libs/algos.c:124730)()\n    639 \n    640 \n    641 \n    642 \n    643 \n--> 644 \n    645 \n    646 \n    647 \n    648 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/_libs/algos.cpython-36m-darwin.so in View.MemoryView.memoryview.__cinit__ (pandas/_libs/algos.c:120965)()\n    340 \n    341 \n    342 \n    343 \n    344 \n--> 345 \n    346 \n    347 \n    348 \n    349 \n\nValueError: buffer source array is read-only\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    681\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m'timeout'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetfullargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Wed Aug  2 18:31:58 2017\nPID: 35370Python 3.6.1: /Users/gstoddard/anaconda/envs/standard_py3_env/bin/python\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('feature_encoder', DropString_E...None,\n            verbose=0, warm_start=False))]),               x1        x2        x3        x4  ...160 -2.339500        a\n\n[200000 rows x 6 columns], memmap([0, 1, 0, ..., 0, 1, 1]), <function _passthrough_scorer>, memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999]), array([    0,     1,     2, ..., 40168, 40171, 40174]), 1, {'clf__n_estimators': 10}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('feature_encoder', DropString_E...None,\n            verbose=0, warm_start=False))]),               x1        x2        x3        x4  ...160 -2.339500        a\n\n[200000 rows x 6 columns], memmap([0, 1, 0, ..., 0, 1, 1]), <function _passthrough_scorer>, memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999]), array([    0,     1,     2, ..., 40168, 40171, 40174]), 1, {'clf__n_estimators': 10})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('feature_encoder', DropString_E...None,\n            verbose=0, warm_start=False))]), X=              x1        x2        x3        x4  ...160 -2.339500        a\n\n[200000 rows x 6 columns], y=memmap([0, 1, 0, ..., 0, 1, 1]), scorer=<function _passthrough_scorer>, train=memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999]), test=array([    0,     1,     2, ..., 40168, 40171, 40174]), verbose=1, parameters={'clf__n_estimators': 10}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    226     if parameters is not None:\n    227         estimator.set_params(**parameters)\n    228 \n    229     start_time = time.time()\n    230 \n--> 231     X_train, y_train = _safe_split(estimator, X, y, train)\n        X_train = undefined\n        y_train = undefined\n        estimator = Pipeline(steps=[('feature_encoder', DropString_E...None,\n            verbose=0, warm_start=False))])\n        X =               x1        x2        x3        x4  ...160 -2.339500        a\n\n[200000 rows x 6 columns]\n        y = memmap([0, 1, 0, ..., 0, 1, 1])\n        train = memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999])\n    232     X_test, y_test = _safe_split(estimator, X, y, test, train)\n    233 \n    234     try:\n    235         if y_train is None:\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/utils/metaestimators.py in _safe_split(estimator=Pipeline(steps=[('feature_encoder', DropString_E...None,\n            verbose=0, warm_start=False))]), X=              x1        x2        x3        x4  ...160 -2.339500        a\n\n[200000 rows x 6 columns], y=memmap([0, 1, 0, ..., 0, 1, 1]), indices=memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999]), train_indices=None)\n    103             if train_indices is None:\n    104                 X_subset = X[np.ix_(indices, indices)]\n    105             else:\n    106                 X_subset = X[np.ix_(indices, train_indices)]\n    107         else:\n--> 108             X_subset = safe_indexing(X, indices)\n        X_subset = undefined\n        X =               x1        x2        x3        x4  ...160 -2.339500        a\n\n[200000 rows x 6 columns]\n        indices = memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999])\n    109 \n    110     if y is not None:\n    111         y_subset = safe_indexing(y, indices)\n    112     else:\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/utils/__init__.py in safe_indexing(X=              x1        x2        x3        x4  ...160 -2.339500        a\n\n[200000 rows x 6 columns], indices=memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999]))\n    100         except ValueError:\n    101             # Cython typed memoryviews internally used in pandas do not support\n    102             # readonly buffers.\n    103             warnings.warn(\"Copying input dataframe for slicing.\",\n    104                           DataConversionWarning)\n--> 105             return X.copy().iloc[indices]\n        X.copy.iloc = undefined\n        indices = memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999])\n    106     elif hasattr(X, \"shape\"):\n    107         if hasattr(X, 'take') and (hasattr(indices, 'dtype') and\n    108                                    indices.dtype.kind == 'i'):\n    109             # This is often substantially faster than X[indices]\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self=<pandas.core.indexing._iLocIndexer object>, key=memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999]))\n   1323             except (KeyError, IndexError):\n   1324                 pass\n   1325             return self._getitem_tuple(key)\n   1326         else:\n   1327             key = com._apply_if_callable(key, self.obj)\n-> 1328             return self._getitem_axis(key, axis=0)\n        self._getitem_axis = <bound method _iLocIndexer._getitem_axis of <pandas.core.indexing._iLocIndexer object>>\n        key = memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999])\n   1329 \n   1330     def _is_scalar_access(self, key):\n   1331         raise NotImplementedError()\n   1332 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self=<pandas.core.indexing._iLocIndexer object>, key=memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999]), axis=0)\n   1733             self._has_valid_type(key, axis)\n   1734             return self._getbool_axis(key, axis=axis)\n   1735 \n   1736         # a list of integers\n   1737         elif is_list_like_indexer(key):\n-> 1738             return self._get_list_axis(key, axis=axis)\n        self._get_list_axis = <bound method _iLocIndexer._get_list_axis of <pandas.core.indexing._iLocIndexer object>>\n        key = memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999])\n        axis = 0\n   1739 \n   1740         # a single integer\n   1741         else:\n   1742             key = self._convert_scalar_indexer(key, axis)\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/indexing.py in _get_list_axis(self=<pandas.core.indexing._iLocIndexer object>, key=memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999]), axis=0)\n   1710         Returns\n   1711         -------\n   1712         Series object\n   1713         \"\"\"\n   1714         try:\n-> 1715             return self.obj.take(key, axis=axis, convert=False)\n        self.obj.take = <bound method NDFrame.take of               x1  ...60 -2.339500        a\n\n[200000 rows x 6 columns]>\n        key = memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999])\n        axis = 0\n   1716         except IndexError:\n   1717             # re-raise with different error message\n   1718             raise IndexError(\"positional indexers are out-of-bounds\")\n   1719 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/generic.py in take(self=              x1        x2        x3        x4  ...160 -2.339500        a\n\n[200000 rows x 6 columns], indices=memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999]), axis=0, convert=False, is_copy=True, **kwargs={})\n   1923         \"\"\"\n   1924         nv.validate_take(tuple(), kwargs)\n   1925         self._consolidate_inplace()\n   1926         new_data = self._data.take(indices,\n   1927                                    axis=self._get_block_manager_axis(axis),\n-> 1928                                    convert=True, verify=True)\n        convert = False\n   1929         result = self._constructor(new_data).__finalize__(self)\n   1930 \n   1931         # maybe set copy if we didn't actually change the index\n   1932         if is_copy:\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py in take(self=BlockManager\nItems: Index(['x1', 'x2', 'x3', 'x4...tBlock: slice(5, 6, 1), 1 x 200000, dtype: object, indexer=memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999]), axis=1, verify=True, convert=True)\n   4006                 raise Exception('Indices must be nonzero and less than '\n   4007                                 'the axis length')\n   4008 \n   4009         new_labels = self.axes[axis].take(indexer)\n   4010         return self.reindex_indexer(new_axis=new_labels, indexer=indexer,\n-> 4011                                     axis=axis, allow_dups=True)\n        axis = 1\n   4012 \n   4013     def merge(self, other, lsuffix='', rsuffix=''):\n   4014         if not self._is_indexed_like(other):\n   4015             raise AssertionError('Must have same axes to merge managers')\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py in reindex_indexer(self=BlockManager\nItems: Index(['x1', 'x2', 'x3', 'x4...tBlock: slice(5, 6, 1), 1 x 200000, dtype: object, new_axis=Int64Index([ 39804,  39805,  39808,  39816,  398...199999],\n           dtype='int64', length=159999), indexer=memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999]), axis=1, fill_value=None, allow_dups=True, copy=True)\n   3892             new_blocks = self._slice_take_blocks_ax0(indexer,\n   3893                                                      fill_tuple=(fill_value,))\n   3894         else:\n   3895             new_blocks = [blk.take_nd(indexer, axis=axis, fill_tuple=(\n   3896                 fill_value if fill_value is not None else blk.fill_value,))\n-> 3897                 for blk in self.blocks]\n        self.blocks = (FloatBlock: slice(0, 5, 1), 5 x 200000, dtype: float64, ObjectBlock: slice(5, 6, 1), 1 x 200000, dtype: object)\n   3898 \n   3899         new_axes = list(self.axes)\n   3900         new_axes[axis] = new_axis\n   3901         return self.__class__(new_blocks, new_axes)\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py in <listcomp>(.0=<tuple_iterator object>)\n   3892             new_blocks = self._slice_take_blocks_ax0(indexer,\n   3893                                                      fill_tuple=(fill_value,))\n   3894         else:\n   3895             new_blocks = [blk.take_nd(indexer, axis=axis, fill_tuple=(\n   3896                 fill_value if fill_value is not None else blk.fill_value,))\n-> 3897                 for blk in self.blocks]\n        blk = FloatBlock: slice(0, 5, 1), 5 x 200000, dtype: float64\n   3898 \n   3899         new_axes = list(self.axes)\n   3900         new_axes[axis] = new_axis\n   3901         return self.__class__(new_blocks, new_axes)\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py in take_nd(self=FloatBlock: slice(0, 5, 1), 5 x 200000, dtype: float64, indexer=memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999]), axis=1, new_mgr_locs=None, fill_tuple=(nan,))\n   1041             new_values = algos.take_nd(values, indexer, axis=axis,\n   1042                                        allow_fill=False)\n   1043         else:\n   1044             fill_value = fill_tuple[0]\n   1045             new_values = algos.take_nd(values, indexer, axis=axis,\n-> 1046                                        allow_fill=True, fill_value=fill_value)\n        fill_value = nan\n   1047 \n   1048         if new_mgr_locs is None:\n   1049             if axis == 0:\n   1050                 slc = lib.indexer_as_slice(indexer)\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/algorithms.py in take_nd(arr=memmap([[ 0.23953029, -0.50635937,  1.40387008, ... 1.38955039,\n         -0.74704499, -2.33949991]]), indexer=memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999]), axis=1, out=array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n    ...0.],\n       [ 0.,  0.,  0., ...,  0.,  0.,  0.]]), fill_value=nan, mask_info=None, allow_fill=True)\n   1466         else:\n   1467             out = np.empty(out_shape, dtype=dtype)\n   1468 \n   1469     func = _get_take_nd_function(arr.ndim, arr.dtype, out.dtype, axis=axis,\n   1470                                  mask_info=mask_info)\n-> 1471     func(arr, indexer, out, fill_value)\n        func = <built-in function take_2d_axis1_float64_float64>\n        arr = memmap([[ 0.23953029, -0.50635937,  1.40387008, ... 1.38955039,\n         -0.74704499, -2.33949991]])\n        indexer = memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999])\n        out = array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n    ...0.],\n       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])\n        fill_value = nan\n   1472 \n   1473     if flip_order:\n   1474         out = out.T\n   1475     return out\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/_libs/algos.cpython-36m-darwin.so in pandas._libs.algos.take_2d_axis1_float64_float64 (pandas/_libs/algos.c:111160)()\n   4629 \n   4630 \n   4631 \n   4632 \n   4633 \n-> 4634 \n   4635 \n   4636 \n   4637 \n   4638 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/_libs/algos.cpython-36m-darwin.so in View.MemoryView.memoryview_cwrapper (pandas/_libs/algos.c:124730)()\n    639 \n    640 \n    641 \n    642 \n    643 \n--> 644 \n    645 \n    646 \n    647 \n    648 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/_libs/algos.cpython-36m-darwin.so in View.MemoryView.memoryview.__cinit__ (pandas/_libs/algos.c:120965)()\n    340 \n    341 \n    342 \n    343 \n    344 \n--> 345 \n    346 \n    347 \n    348 \n    349 \n\nValueError: buffer source array is read-only\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d5101a6a0bf9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtest\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \"\"\"\n\u001b[0;32m--> 945\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                   \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m--> 564\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m           for train, test in cv_iter)\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x10e8bd030, file \"/Use...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/Users/gstoddard/anaconda/envs/standard_py3_env/...ges/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/Users/gstod.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x10e8bd030, file \"/Use...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/Users/gstoddard/anaconda/envs/standard_py3_env/...ges/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/Users/gstod.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n     17 \n     18 \n     19 \n     20 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'class DropString_Encoder(BaseEstimator, Transfor...ram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 8, 2, 22, 31, 58, 246994, tzinfo=tzutc()), 'msg_id': '43497E3ACF714AAB98CB24992E51E772', 'msg_type': 'execute_request', 'session': 'A09FD675E3EA46CB837CBE1D3E75F32E', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '43497E3ACF714AAB98CB24992E51E772', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'A09FD675E3EA46CB837CBE1D3E75F32E']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'class DropString_Encoder(BaseEstimator, Transfor...ram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 8, 2, 22, 31, 58, 246994, tzinfo=tzutc()), 'msg_id': '43497E3ACF714AAB98CB24992E51E772', 'msg_type': 'execute_request', 'session': 'A09FD675E3EA46CB837CBE1D3E75F32E', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '43497E3ACF714AAB98CB24992E51E772', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'A09FD675E3EA46CB837CBE1D3E75F32E'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'class DropString_Encoder(BaseEstimator, Transfor...ram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)\\n', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 8, 2, 22, 31, 58, 246994, tzinfo=tzutc()), 'msg_id': '43497E3ACF714AAB98CB24992E51E772', 'msg_type': 'execute_request', 'session': 'A09FD675E3EA46CB837CBE1D3E75F32E', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '43497E3ACF714AAB98CB24992E51E772', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='class DropString_Encoder(BaseEstimator, Transfor...ram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)\\n', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'class DropString_Encoder(BaseEstimator, Transfor...ram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)\\n'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('class DropString_Encoder(BaseEstimator, Transfor...ram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)\\n',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('class DropString_Encoder(BaseEstimator, Transfor...ram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)\\n',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='class DropString_Encoder(BaseEstimator, Transfor...ram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)\\n', store_history=True, silent=False, shell_futures=True)\n   2678                 self.displayhook.exec_result = result\n   2679 \n   2680                 # Execute the user code\n   2681                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2682                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2683                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2684                 \n   2685                 self.last_execution_succeeded = not has_raised\n   2686 \n   2687                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.ClassDef object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-5-d5101a6a0bf9>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 119632668, execution_..._before_exec=None error_in_exec=None result=None>)\n   2788                     return True\n   2789 \n   2790             for i, node in enumerate(to_run_interactive):\n   2791                 mod = ast.Interactive([node])\n   2792                 code = compiler(mod, cell_name, \"single\")\n-> 2793                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x1196b6540, file \"<ipython-input-5-d5101a6a0bf9>\", line 30>\n        result = <ExecutionResult object at 119632668, execution_..._before_exec=None error_in_exec=None result=None>\n   2794                     return True\n   2795 \n   2796             # Flush softspace\n   2797             if softspace(sys.stdout, 0):\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x1196b6540, file \"<ipython-input-5-d5101a6a0bf9>\", line 30>, result=<ExecutionResult object at 119632668, execution_..._before_exec=None error_in_exec=None result=None>)\n   2842         outflag = True  # happens in more places, so it's easier as default\n   2843         try:\n   2844             try:\n   2845                 self.hooks.pre_run_code_hook()\n   2846                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2847                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x1196b6540, file \"<ipython-input-5-d5101a6a0bf9>\", line 30>\n        self.user_global_ns = {'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'DataFrame_Encoder': <class '__main__.DataFrame_Encoder'>, 'DictVectorizer': <class 'sklearn.feature_extraction.dict_vectorizer.DictVectorizer'>, 'DropString_Encoder': <class '__main__.DropString_Encoder'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import pandas as pd\\n\\nfrom sklearn.model_selectio...raction import DictVectorizer\\n\\nimport numpy as np', 'class DataFrame_Encoder(BaseEstimator, Transform..., categorical_df],axis=1)\\n        return new_data', 'x,y = make_classification(n_samples=200000,n_fea...aram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)', 'x,y = make_classification(n_samples=200000,n_fea...aram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)', 'class DropString_Encoder(BaseEstimator, Transfor...aram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)'], 'Out': {}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'TransformerMixin': <class 'sklearn.base.TransformerMixin'>, ...}\n        self.user_ns = {'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'DataFrame_Encoder': <class '__main__.DataFrame_Encoder'>, 'DictVectorizer': <class 'sklearn.feature_extraction.dict_vectorizer.DictVectorizer'>, 'DropString_Encoder': <class '__main__.DropString_Encoder'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import pandas as pd\\n\\nfrom sklearn.model_selectio...raction import DictVectorizer\\n\\nimport numpy as np', 'class DataFrame_Encoder(BaseEstimator, Transform..., categorical_df],axis=1)\\n        return new_data', 'x,y = make_classification(n_samples=200000,n_fea...aram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)', 'x,y = make_classification(n_samples=200000,n_fea...aram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)', 'class DropString_Encoder(BaseEstimator, Transfor...aram_grid,cv=5,n_jobs=2,verbose=1)\\n\\nclf.fit(df,y)'], 'Out': {}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'TransformerMixin': <class 'sklearn.base.TransformerMixin'>, ...}\n   2848             finally:\n   2849                 # Reset our crash handler in place\n   2850                 sys.excepthook = old_excepthook\n   2851         except SystemExit as e:\n\n...........................................................................\n/Users/gstoddard/sklearn_bug/<ipython-input-5-d5101a6a0bf9> in <module>()\n     25         ('clf',base_clf)\n     26 ])\n     27 \n     28 clf = GridSearchCV(pipeline, param_grid,cv=5,n_jobs=2,verbose=1)\n     29 \n---> 30 clf.fit(df,y)\n     31 \n     32 \n     33 \n     34 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...train_score=True,\n       scoring=None, verbose=1), X=              x1        x2        x3        x4  ...160 -2.339500        a\n\n[200000 rows x 6 columns], y=array([0, 1, 0, ..., 0, 1, 1]), groups=None)\n    940 \n    941         groups : array-like, with shape (n_samples,), optional\n    942             Group labels for the samples used while splitting the dataset into\n    943             train/test set.\n    944         \"\"\"\n--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))\n        self._fit = <bound method BaseSearchCV._fit of GridSearchCV(...rain_score=True,\n       scoring=None, verbose=1)>\n        X =               x1        x2        x3        x4  ...160 -2.339500        a\n\n[200000 rows x 6 columns]\n        y = array([0, 1, 0, ..., 0, 1, 1])\n        groups = None\n        self.param_grid = {'clf__n_estimators': [10, 100]}\n    946 \n    947 \n    948 class RandomizedSearchCV(BaseSearchCV):\n    949     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...train_score=True,\n       scoring=None, verbose=1), X=              x1        x2        x3        x4  ...160 -2.339500        a\n\n[200000 rows x 6 columns], y=array([0, 1, 0, ..., 0, 1, 1]), groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)\n    559                                   fit_params=self.fit_params,\n    560                                   return_train_score=self.return_train_score,\n    561                                   return_n_test_samples=True,\n    562                                   return_times=True, return_parameters=True,\n    563                                   error_score=self.error_score)\n--> 564           for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>\n    565           for train, test in cv_iter)\n    566 \n    567         # if one choose to see train score, \"out\" will contain train score info\n    568         if self.return_train_score:\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=2), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=2)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Wed Aug  2 18:31:58 2017\nPID: 35370Python 3.6.1: /Users/gstoddard/anaconda/envs/standard_py3_env/bin/python\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('feature_encoder', DropString_E...None,\n            verbose=0, warm_start=False))]),               x1        x2        x3        x4  ...160 -2.339500        a\n\n[200000 rows x 6 columns], memmap([0, 1, 0, ..., 0, 1, 1]), <function _passthrough_scorer>, memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999]), array([    0,     1,     2, ..., 40168, 40171, 40174]), 1, {'clf__n_estimators': 10}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('feature_encoder', DropString_E...None,\n            verbose=0, warm_start=False))]),               x1        x2        x3        x4  ...160 -2.339500        a\n\n[200000 rows x 6 columns], memmap([0, 1, 0, ..., 0, 1, 1]), <function _passthrough_scorer>, memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999]), array([    0,     1,     2, ..., 40168, 40171, 40174]), 1, {'clf__n_estimators': 10})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('feature_encoder', DropString_E...None,\n            verbose=0, warm_start=False))]), X=              x1        x2        x3        x4  ...160 -2.339500        a\n\n[200000 rows x 6 columns], y=memmap([0, 1, 0, ..., 0, 1, 1]), scorer=<function _passthrough_scorer>, train=memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999]), test=array([    0,     1,     2, ..., 40168, 40171, 40174]), verbose=1, parameters={'clf__n_estimators': 10}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    226     if parameters is not None:\n    227         estimator.set_params(**parameters)\n    228 \n    229     start_time = time.time()\n    230 \n--> 231     X_train, y_train = _safe_split(estimator, X, y, train)\n        X_train = undefined\n        y_train = undefined\n        estimator = Pipeline(steps=[('feature_encoder', DropString_E...None,\n            verbose=0, warm_start=False))])\n        X =               x1        x2        x3        x4  ...160 -2.339500        a\n\n[200000 rows x 6 columns]\n        y = memmap([0, 1, 0, ..., 0, 1, 1])\n        train = memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999])\n    232     X_test, y_test = _safe_split(estimator, X, y, test, train)\n    233 \n    234     try:\n    235         if y_train is None:\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/utils/metaestimators.py in _safe_split(estimator=Pipeline(steps=[('feature_encoder', DropString_E...None,\n            verbose=0, warm_start=False))]), X=              x1        x2        x3        x4  ...160 -2.339500        a\n\n[200000 rows x 6 columns], y=memmap([0, 1, 0, ..., 0, 1, 1]), indices=memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999]), train_indices=None)\n    103             if train_indices is None:\n    104                 X_subset = X[np.ix_(indices, indices)]\n    105             else:\n    106                 X_subset = X[np.ix_(indices, train_indices)]\n    107         else:\n--> 108             X_subset = safe_indexing(X, indices)\n        X_subset = undefined\n        X =               x1        x2        x3        x4  ...160 -2.339500        a\n\n[200000 rows x 6 columns]\n        indices = memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999])\n    109 \n    110     if y is not None:\n    111         y_subset = safe_indexing(y, indices)\n    112     else:\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/sklearn/utils/__init__.py in safe_indexing(X=              x1        x2        x3        x4  ...160 -2.339500        a\n\n[200000 rows x 6 columns], indices=memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999]))\n    100         except ValueError:\n    101             # Cython typed memoryviews internally used in pandas do not support\n    102             # readonly buffers.\n    103             warnings.warn(\"Copying input dataframe for slicing.\",\n    104                           DataConversionWarning)\n--> 105             return X.copy().iloc[indices]\n        X.copy.iloc = undefined\n        indices = memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999])\n    106     elif hasattr(X, \"shape\"):\n    107         if hasattr(X, 'take') and (hasattr(indices, 'dtype') and\n    108                                    indices.dtype.kind == 'i'):\n    109             # This is often substantially faster than X[indices]\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self=<pandas.core.indexing._iLocIndexer object>, key=memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999]))\n   1323             except (KeyError, IndexError):\n   1324                 pass\n   1325             return self._getitem_tuple(key)\n   1326         else:\n   1327             key = com._apply_if_callable(key, self.obj)\n-> 1328             return self._getitem_axis(key, axis=0)\n        self._getitem_axis = <bound method _iLocIndexer._getitem_axis of <pandas.core.indexing._iLocIndexer object>>\n        key = memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999])\n   1329 \n   1330     def _is_scalar_access(self, key):\n   1331         raise NotImplementedError()\n   1332 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self=<pandas.core.indexing._iLocIndexer object>, key=memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999]), axis=0)\n   1733             self._has_valid_type(key, axis)\n   1734             return self._getbool_axis(key, axis=axis)\n   1735 \n   1736         # a list of integers\n   1737         elif is_list_like_indexer(key):\n-> 1738             return self._get_list_axis(key, axis=axis)\n        self._get_list_axis = <bound method _iLocIndexer._get_list_axis of <pandas.core.indexing._iLocIndexer object>>\n        key = memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999])\n        axis = 0\n   1739 \n   1740         # a single integer\n   1741         else:\n   1742             key = self._convert_scalar_indexer(key, axis)\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/indexing.py in _get_list_axis(self=<pandas.core.indexing._iLocIndexer object>, key=memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999]), axis=0)\n   1710         Returns\n   1711         -------\n   1712         Series object\n   1713         \"\"\"\n   1714         try:\n-> 1715             return self.obj.take(key, axis=axis, convert=False)\n        self.obj.take = <bound method NDFrame.take of               x1  ...60 -2.339500        a\n\n[200000 rows x 6 columns]>\n        key = memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999])\n        axis = 0\n   1716         except IndexError:\n   1717             # re-raise with different error message\n   1718             raise IndexError(\"positional indexers are out-of-bounds\")\n   1719 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/generic.py in take(self=              x1        x2        x3        x4  ...160 -2.339500        a\n\n[200000 rows x 6 columns], indices=memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999]), axis=0, convert=False, is_copy=True, **kwargs={})\n   1923         \"\"\"\n   1924         nv.validate_take(tuple(), kwargs)\n   1925         self._consolidate_inplace()\n   1926         new_data = self._data.take(indices,\n   1927                                    axis=self._get_block_manager_axis(axis),\n-> 1928                                    convert=True, verify=True)\n        convert = False\n   1929         result = self._constructor(new_data).__finalize__(self)\n   1930 \n   1931         # maybe set copy if we didn't actually change the index\n   1932         if is_copy:\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py in take(self=BlockManager\nItems: Index(['x1', 'x2', 'x3', 'x4...tBlock: slice(5, 6, 1), 1 x 200000, dtype: object, indexer=memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999]), axis=1, verify=True, convert=True)\n   4006                 raise Exception('Indices must be nonzero and less than '\n   4007                                 'the axis length')\n   4008 \n   4009         new_labels = self.axes[axis].take(indexer)\n   4010         return self.reindex_indexer(new_axis=new_labels, indexer=indexer,\n-> 4011                                     axis=axis, allow_dups=True)\n        axis = 1\n   4012 \n   4013     def merge(self, other, lsuffix='', rsuffix=''):\n   4014         if not self._is_indexed_like(other):\n   4015             raise AssertionError('Must have same axes to merge managers')\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py in reindex_indexer(self=BlockManager\nItems: Index(['x1', 'x2', 'x3', 'x4...tBlock: slice(5, 6, 1), 1 x 200000, dtype: object, new_axis=Int64Index([ 39804,  39805,  39808,  39816,  398...199999],\n           dtype='int64', length=159999), indexer=memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999]), axis=1, fill_value=None, allow_dups=True, copy=True)\n   3892             new_blocks = self._slice_take_blocks_ax0(indexer,\n   3893                                                      fill_tuple=(fill_value,))\n   3894         else:\n   3895             new_blocks = [blk.take_nd(indexer, axis=axis, fill_tuple=(\n   3896                 fill_value if fill_value is not None else blk.fill_value,))\n-> 3897                 for blk in self.blocks]\n        self.blocks = (FloatBlock: slice(0, 5, 1), 5 x 200000, dtype: float64, ObjectBlock: slice(5, 6, 1), 1 x 200000, dtype: object)\n   3898 \n   3899         new_axes = list(self.axes)\n   3900         new_axes[axis] = new_axis\n   3901         return self.__class__(new_blocks, new_axes)\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py in <listcomp>(.0=<tuple_iterator object>)\n   3892             new_blocks = self._slice_take_blocks_ax0(indexer,\n   3893                                                      fill_tuple=(fill_value,))\n   3894         else:\n   3895             new_blocks = [blk.take_nd(indexer, axis=axis, fill_tuple=(\n   3896                 fill_value if fill_value is not None else blk.fill_value,))\n-> 3897                 for blk in self.blocks]\n        blk = FloatBlock: slice(0, 5, 1), 5 x 200000, dtype: float64\n   3898 \n   3899         new_axes = list(self.axes)\n   3900         new_axes[axis] = new_axis\n   3901         return self.__class__(new_blocks, new_axes)\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/internals.py in take_nd(self=FloatBlock: slice(0, 5, 1), 5 x 200000, dtype: float64, indexer=memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999]), axis=1, new_mgr_locs=None, fill_tuple=(nan,))\n   1041             new_values = algos.take_nd(values, indexer, axis=axis,\n   1042                                        allow_fill=False)\n   1043         else:\n   1044             fill_value = fill_tuple[0]\n   1045             new_values = algos.take_nd(values, indexer, axis=axis,\n-> 1046                                        allow_fill=True, fill_value=fill_value)\n        fill_value = nan\n   1047 \n   1048         if new_mgr_locs is None:\n   1049             if axis == 0:\n   1050                 slc = lib.indexer_as_slice(indexer)\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/core/algorithms.py in take_nd(arr=memmap([[ 0.23953029, -0.50635937,  1.40387008, ... 1.38955039,\n         -0.74704499, -2.33949991]]), indexer=memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999]), axis=1, out=array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n    ...0.],\n       [ 0.,  0.,  0., ...,  0.,  0.,  0.]]), fill_value=nan, mask_info=None, allow_fill=True)\n   1466         else:\n   1467             out = np.empty(out_shape, dtype=dtype)\n   1468 \n   1469     func = _get_take_nd_function(arr.ndim, arr.dtype, out.dtype, axis=axis,\n   1470                                  mask_info=mask_info)\n-> 1471     func(arr, indexer, out, fill_value)\n        func = <built-in function take_2d_axis1_float64_float64>\n        arr = memmap([[ 0.23953029, -0.50635937,  1.40387008, ... 1.38955039,\n         -0.74704499, -2.33949991]])\n        indexer = memmap([ 39804,  39805,  39808, ..., 199997, 199998, 199999])\n        out = array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n    ...0.],\n       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])\n        fill_value = nan\n   1472 \n   1473     if flip_order:\n   1474         out = out.T\n   1475     return out\n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/_libs/algos.cpython-36m-darwin.so in pandas._libs.algos.take_2d_axis1_float64_float64 (pandas/_libs/algos.c:111160)()\n   4629 \n   4630 \n   4631 \n   4632 \n   4633 \n-> 4634 \n   4635 \n   4636 \n   4637 \n   4638 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/_libs/algos.cpython-36m-darwin.so in View.MemoryView.memoryview_cwrapper (pandas/_libs/algos.c:124730)()\n    639 \n    640 \n    641 \n    642 \n    643 \n--> 644 \n    645 \n    646 \n    647 \n    648 \n\n...........................................................................\n/Users/gstoddard/anaconda/envs/standard_py3_env/lib/python3.6/site-packages/pandas/_libs/algos.cpython-36m-darwin.so in View.MemoryView.memoryview.__cinit__ (pandas/_libs/algos.c:120965)()\n    340 \n    341 \n    342 \n    343 \n    344 \n--> 345 \n    346 \n    347 \n    348 \n    349 \n\nValueError: buffer source array is read-only\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "class DropString_Encoder(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self,df,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,df):\n",
    "        non_string_cols = df.select_dtypes(exclude=[object]).columns.values\n",
    "        return df[non_string_cols]\n",
    "\n",
    "\n",
    "    \n",
    "x,y = make_classification(n_samples=200000,n_features=5)\n",
    "\n",
    "numeric_features = ['x1','x2','x3','x4','x5']\n",
    "string_features = ['category']\n",
    "\n",
    "df = pd.DataFrame(data=x,columns=numeric_features)\n",
    "df['category'] = 'a'\n",
    "\n",
    "base_clf = RandomForestClassifier(n_jobs=4)\n",
    "param_grid = {'clf__n_estimators':[10,100]}\n",
    "\n",
    "pipeline = Pipeline([\n",
    "        ('feature_encoder',DropString_Encoder()),\n",
    "        ('clf',base_clf)\n",
    "])\n",
    "\n",
    "clf = GridSearchCV(pipeline, param_grid,cv=5,n_jobs=2,verbose=1)\n",
    "\n",
    "clf.fit(df,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 4: Works\n",
    " \n",
    "In line 20, we drop the one Object column and only keep the numeric ones. Once we do that, things work fine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__ called\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "__init__ called\n",
      "__init__ called\n",
      "__init__ called\n",
      "Fit called\n",
      "Fit called\n",
      "Transform called\n",
      "Transform called\n",
      "Transform called\n",
      "Transform called\n",
      "Transform called\n",
      "Transform called\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    4.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    4.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__ called\n",
      "Fit called\n",
      "Transform called\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('feature_encoder', DataFrame_Encoder(categorical_cols_=[],\n",
       "         numeric_cols_=['x1', 'x2', 'x3', 'x4', 'x5'])), ('clf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impuri...imators=10, n_jobs=4, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False))]),\n",
       "       fit_params={}, iid=True, n_jobs=2,\n",
       "       param_grid={'clf__n_estimators': [10]}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score=True, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = make_classification(n_samples=200000,n_features=5)\n",
    "\n",
    "numeric_features = ['x1','x2','x3','x4','x5']\n",
    "string_features = []\n",
    "\n",
    "df = pd.DataFrame(data=x,columns=numeric_features)\n",
    "df['category'] = 'a'\n",
    "\n",
    "base_clf = RandomForestClassifier(n_jobs=4)\n",
    "param_grid = {'clf__n_estimators':[10]}\n",
    "\n",
    "pipeline = Pipeline([\n",
    "        ('feature_encoder',DataFrame_Encoder()),\n",
    "        ('clf',base_clf)\n",
    "])\n",
    "pipeline.set_params(feature_encoder__categorical_cols_=string_features, feature_encoder__numeric_cols_=numeric_features)\n",
    "\n",
    "clf = GridSearchCV(pipeline, param_grid,cv=2,n_jobs=2,verbose=1)\n",
    "\n",
    "temp_df = df[numeric_features]\n",
    "\n",
    "clf.fit(temp_df,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 5: Works\n",
    " \n",
    "This is the full example but we simply decrease the size of the dataset and everything works fine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__ called\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "__init__ called\n",
      "Fit called\n",
      "Fit called\n",
      "Transform called\n",
      "Transform called\n",
      "__init__ called\n",
      "__init__ called\n",
      "Transform called\n",
      "Transform called\n",
      "Transform called\n",
      "Transform called\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__ called\n",
      "Fit called\n",
      "Transform called\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('feature_encoder', DataFrame_Encoder(categorical_cols_=['category'],\n",
       "         numeric_cols_=['x1', 'x2', 'x3', 'x4', 'x5'])), ('clf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            ...imators=10, n_jobs=4, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False))]),\n",
       "       fit_params={}, iid=True, n_jobs=2,\n",
       "       param_grid={'clf__n_estimators': [10]}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score=True, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = make_classification(n_samples=2000,n_features=5)\n",
    "\n",
    "numeric_features = ['x1','x2','x3','x4','x5']\n",
    "string_features = ['category']\n",
    "\n",
    "df = pd.DataFrame(data=x,columns=numeric_features)\n",
    "df['category'] = 'a'\n",
    "\n",
    "base_clf = RandomForestClassifier(n_jobs=4)\n",
    "param_grid = {'clf__n_estimators':[10]}\n",
    "\n",
    "pipeline = Pipeline([\n",
    "        ('feature_encoder',DataFrame_Encoder()),\n",
    "        ('clf',base_clf)\n",
    "])\n",
    "pipeline.set_params(feature_encoder__categorical_cols_=string_features, feature_encoder__numeric_cols_=numeric_features)\n",
    "\n",
    "clf = GridSearchCV(pipeline, param_grid,cv=2,n_jobs=2,verbose=1)\n",
    "\n",
    "\n",
    "clf.fit(df,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Darwin-15.6.0-x86_64-i386-64bit\n",
      "Python 3.6.1 |Continuum Analytics, Inc.| (default, May 11 2017, 13:04:09) \n",
      "[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)]\n",
      "NumPy 1.13.1\n",
      "SciPy 0.19.1\n",
      "Scikit-Learn 0.18.2\n"
     ]
    }
   ],
   "source": [
    "import platform; print(platform.platform())\n",
    "import sys; print(\"Python\", sys.version)\n",
    "import numpy; print(\"NumPy\", numpy.__version__)\n",
    "import scipy; print(\"SciPy\", scipy.__version__)\n",
    "import sklearn; print(\"Scikit-Learn\", sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
